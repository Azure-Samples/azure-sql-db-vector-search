{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.8",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Create, store and query OpenAI embeddings in Azure SQL DB\n",
                "\n",
                "This notebook will teach you to:\n",
                "\n",
                "- How to create embeddings from content using the Azure OpenAI API\n",
                "- How to use Azure SQL DB as a vector database and store embeddings data in SQL & perform similarity search\n",
                "- How to use embeddings retrieved from a vector database to augment LLM generation.\n",
                "\n",
                "In this tutorial we will be using the [Fine Foods Review Dataset](https:\\www.kaggle.com\\datasets\\snap\\amazon-fine-food-reviews) available on Kaggle. This dataset consists of reviews of fine foods from amazon\n",
                "\n",
                "We will be using a [smaller sample](https://github.com/Azure-Samples/azure-sql-db-vector-search/blob/a181e15337402e568f4fc66fe5941e5973171972/VectorSearch_Notebooks/Datasets/Reviews.csv) for the tutorial. If you want to skip the steps of generating embeddings & directly load it in SQLDB to perform similarity search you can download the  [finefoodembeddings.csv](https:\\github.com\\Azure-Samples\\azure-sql-db-vector-search\\blob\\a181e15337402e568f4fc66fe5941e5973171972\\VectorSearch_Notebooks\\Datasets\\finefoodembeddings.csv)  file that contains generated embeddings using text-embedding-small model from Azure OpenAI.\n",
                "\n",
                "This notebook contains some code snippets from the documentation [Explore Azure OpenAI Service embeddings Tutorial](https:\\learn.microsoft.com\\en-us\\azure\\ai-services\\openai\\tutorials\\embeddings?tabs=python-new%2Ccommand-line&pivots=programming-language-python)\n",
                "\n",
                "## Prerequisites:\n",
                "\n",
                "- An Azure subscription - [Create one for free](https:\\azure.microsoft.com\\free\\cognitive-services?azure-portal=true)\n",
                "    \n",
                "- Azure SQL Database - [Create one for free](https:\\learn.microsoft.com\\azure\\azure-sql\\database\\free-offer?view=azuresql)\n",
                "    \n",
                "\n",
                "### If you want to generate embeddings on your own & use the chatbot then you will also need\n",
                "\n",
                "- Access granted to Azure OpenAI in the desired Azure subscription. Currently, access to this service is granted only by application. You can apply for access to Azure OpenAI by completing the form at [https://aka.ms/oai/access](https:\\aka.ms\\oai\\access). Open an issue on this repo to contact us if you have an issue.\n",
                "    \n",
                "- An Azure OpenAI resource with the [embeddings model](https:\\learn.microsoft.com\\en-us\\azure\\ai-services\\openai\\concepts\\models#embeddings-models) like text-embedding-ada-002 or text-embedding-small model. A GPT3.5 model deployed for the [chatcompletion model](https:\\learn.microsoft.com\\en-us\\azure\\ai-services\\openai\\concepts\\models#gpt-35-models). If you don't have a resource the process of creating one is documented in our [resource deployment guide](https:\\learn.microsoft.com\\en-us\\azure\\ai-services\\openai\\how-to\\create-resource).\n",
                "    \n",
                "- [Python 3.7.1 or later version](https:\\www.python.org)\n",
                "    \n",
                "- The following Python libraries: openai, num2words, matplotlib, plotly, scipy, scikit-learn, pandas, tiktoken , pyodbc \n",
                "    \n",
                "- [Jupyter Notebooks](https:\\learn.microsoft.com\\en-us\\azure-data-studio\\notebooks\\notebooks-guidance)"
            ],
            "metadata": {
                "azdata_cell_guid": "a56b4788-b5d4-4314-82b6-9aa5c0bd4c81"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Before we start you ensure you:"
            ],
            "metadata": {
                "azdata_cell_guid": "814fa83c-d746-4c70-9c5d-6af4b9fa5ea6"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Create the table in the database\n",
                "\n",
                "SQL commands are in the [createtable.sql](https:\\github.com\\Azure-Samples\\azure-sql-db-vector-search\\blob\\5314865140dbcb22df8d0d1a8497788f7a5477bc\\VectorSearch_Notebooks\\Python_Notebook_Example\\createtable.sql) script"
            ],
            "metadata": {
                "azdata_cell_guid": "eedcd374-2b80-4d09-b923-a64afb3df41a"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Fill out the .env file with your SQL server and Azure Open AI key and Endpoint values.\n",
                "\n",
                "For this notebook retrieve your Azure Open AI key and endpoint as mentioned [here](https:\\learn.microsoft.com\\en-us\\azure\\ai-services\\openai\\tutorials\\embeddings?tabs=python-new%2Ccommand-line&pivots=programming-language-python#retrieve-key-and-endpoint)\n",
                "\n",
                "For Azure SQL Connection String details-  Navigate to the database pane in the Azure portal and, under Settings, select Connection strings."
            ],
            "metadata": {
                "azdata_cell_guid": "418f24f1-1e37-4dc7-a7e2-d2008ea5851a"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Part 1 - Create embeddings from content using the Azure OpenAI API\n",
                "\n",
                "Note: If you want to skip the steps of generating embeddings & directly load it in SQLDB to perform similarity search you can directly skip to Part 2) Load and Store embeddings in Azure SQL DB"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "b0b8ed3a-2313-469c-a038-4ea72214bf97"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "#Setup the python libraries required for this notebook\r\n",
                "pip install -r requirements.txt"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "59dd0902-a737-4867-b4a3-11c5396a1fad"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "#Load the env details\r\n",
                "from dotenv import load_dotenv\r\n",
                "load_dotenv()\r\n",
                "\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "ab896eec-22dd-4a2d-ad5e-eab1d662fb52",
                "language": "python",
                "tags": []
            },
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 9,
                    "data": {
                        "text/plain": "True"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 9
        },
        {
            "cell_type": "markdown",
            "source": [
                "Lets define the function to generate embeddings from Azure Open AI text-embedding-small model.\n",
                "\n",
                "An embedding is a special format of data representation that can be easily utilized by machine learning models and algorithms. The embedding is an information dense representation of the semantic meaning of a piece of text.\n",
                "\n",
                "Each embedding is a vector of floating point numbers, such that the distance between two embeddings in the vector space is correlated with semantic similarity between two inputs in the original format. For example, if two texts are similar, then their vector representations should also be similar. Embeddings power vector similarity search in Azure SQL Database"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "ef9509c5-f27a-44ec-ade2-a2f8902e18c1"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import os\r\n",
                "import requests\r\n",
                "import sys\r\n",
                "from num2words import num2words\r\n",
                "import pandas as pd\r\n",
                "import numpy as np\r\n",
                "import tiktoken\r\n",
                "from openai import AzureOpenAI\r\n",
                "\r\n",
                "# Assuming openai_url and openai_key are environment variables\r\n",
                "openai_url = os.environ.get('openai_url')\r\n",
                "openai_key = os.environ.get('openai_key')\r\n",
                "\r\n",
                "def get_embedding(text):\r\n",
                "    \"\"\"\r\n",
                "    Get sentence embedding using the Azure OpenAI text-embedding-small model.\r\n",
                "\r\n",
                "    Args:\r\n",
                "        text (str): Text to embed.\r\n",
                "\r\n",
                "    Returns:\r\n",
                "        dict: A dictionary containing the embedding.\r\n",
                "    \"\"\"\r\n",
                "    response = requests.post(openai_url,\r\n",
                "        headers={\"api-key\": openai_key, \"Content-Type\": \"application/json\"},\r\n",
                "        json={\"input\": [text]}  # Embed a single sentence\r\n",
                "    )\r\n",
                "    embedding = response.json()['data'][0]['embedding']\r\n",
                "    return embedding"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "5357f9e6-1a24-474a-b3fc-147441e9b6c8"
            },
            "outputs": [],
            "execution_count": 10
        },
        {
            "cell_type": "markdown",
            "source": [
                "In this tutorial we will be using the Fine Foods Review Dataset. This dataset consists of reviews of fine foods from Amazon.\n",
                "\n",
                "Now we need to read our [Reviews.csv](https:\\github.com\\Azure-Samples\\azure-sql-db-vector-search\\blob\\a181e15337402e568f4fc66fe5941e5973171972\\VectorSearch_Notebooks\\Datasets\\Reviews.csv) file and create a pandas DataFrame. After the initial DataFrame is created, we can view the contents of the table by running the below. For the purpose of the quick embedding generation tutorial we will only use nrows = 500."
            ],
            "metadata": {
                "azdata_cell_guid": "0343bba0-01ea-4537-a793-adaadb904781"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\r\n",
                "\r\n",
                "# load & inspect dataset\r\n",
                "df = pd.read_csv(r\"AzureSQLVectorSearch\\Dataset\\Reviews.csv\" , nrows =500)\r\n",
                "df = df[[\"Id\" , \"Time\", \"ProductId\", \"UserId\", \"Score\", \"Summary\", \"Text\"]]\r\n",
                "df = df.dropna()\r\n",
                "df[\"combined\"] = (\r\n",
                "    \"Title: \" + df.Summary.str.strip() + \"; Content: \" + df.Text.str.strip()\r\n",
                ")\r\n",
                "df.head(10)"
            ],
            "metadata": {
                "azdata_cell_guid": "f6815045-f75d-4bba-960f-f76818baa592",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 9,
                    "data": {
                        "text/plain": "   Id        Time   ProductId          UserId  Score  \\\n0   1  1303862400  B001E4KFG0  A3SGXH7AUHU8GW      5   \n1   2  1346976000  B00813GRG4  A1D87F6ZCVE5NK      1   \n2   3  1219017600  B000LQOCH0   ABXLMWJIXXAIN      4   \n3   4  1307923200  B000UA0QIQ  A395BORC6FGVXV      2   \n4   5  1350777600  B006K2ZZ7K  A1UQRSCLF8GW1T      5   \n5   6  1342051200  B006K2ZZ7K   ADT0SRK1MGOEU      4   \n6   7  1340150400  B006K2ZZ7K  A1SP2KVKFXXRU1      5   \n7   8  1336003200  B006K2ZZ7K  A3JRGQVEQN31IQ      5   \n8   9  1322006400  B000E7L2R4  A1MZYO9TZK0BBI      5   \n9  10  1351209600  B00171APVA  A21BT40VZCCYT4      5   \n\n                                         Summary  \\\n0                          Good Quality Dog Food   \n1                              Not as Advertised   \n2                          \"Delight\" says it all   \n3                                 Cough Medicine   \n4                                    Great taffy   \n5                                     Nice Taffy   \n6  Great!  Just as good as the expensive brands!   \n7                         Wonderful, tasty taffy   \n8                                     Yay Barley   \n9                               Healthy Dog Food   \n\n                                                Text  \\\n0  I have bought several of the Vitality canned d...   \n1  Product arrived labeled as Jumbo Salted Peanut...   \n2  This is a confection that has been around a fe...   \n3  If you are looking for the secret ingredient i...   \n4  Great taffy at a great price.  There was a wid...   \n5  I got a wild hair for taffy and ordered this f...   \n6  This saltwater taffy had great flavors and was...   \n7  This taffy is so good.  It is very soft and ch...   \n8  Right now I'm mostly just sprouting this so my...   \n9  This is a very healthy dog food. Good for thei...   \n\n                                            combined  \n0  Title: Good Quality Dog Food; Content: I have ...  \n1  Title: Not as Advertised; Content: Product arr...  \n2  Title: \"Delight\" says it all; Content: This is...  \n3  Title: Cough Medicine; Content: If you are loo...  \n4  Title: Great taffy; Content: Great taffy at a ...  \n5  Title: Nice Taffy; Content: I got a wild hair ...  \n6  Title: Great!  Just as good as the expensive b...  \n7  Title: Wonderful, tasty taffy; Content: This t...  \n8  Title: Yay Barley; Content: Right now I'm most...  \n9  Title: Healthy Dog Food; Content: This is a ve...  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Time</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>Score</th>\n      <th>Summary</th>\n      <th>Text</th>\n      <th>combined</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1303862400</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>5</td>\n      <td>Good Quality Dog Food</td>\n      <td>I have bought several of the Vitality canned d...</td>\n      <td>Title: Good Quality Dog Food; Content: I have ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1346976000</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>1</td>\n      <td>Not as Advertised</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n      <td>Title: Not as Advertised; Content: Product arr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1219017600</td>\n      <td>B000LQOCH0</td>\n      <td>ABXLMWJIXXAIN</td>\n      <td>4</td>\n      <td>\"Delight\" says it all</td>\n      <td>This is a confection that has been around a fe...</td>\n      <td>Title: \"Delight\" says it all; Content: This is...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1307923200</td>\n      <td>B000UA0QIQ</td>\n      <td>A395BORC6FGVXV</td>\n      <td>2</td>\n      <td>Cough Medicine</td>\n      <td>If you are looking for the secret ingredient i...</td>\n      <td>Title: Cough Medicine; Content: If you are loo...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1350777600</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1UQRSCLF8GW1T</td>\n      <td>5</td>\n      <td>Great taffy</td>\n      <td>Great taffy at a great price.  There was a wid...</td>\n      <td>Title: Great taffy; Content: Great taffy at a ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>1342051200</td>\n      <td>B006K2ZZ7K</td>\n      <td>ADT0SRK1MGOEU</td>\n      <td>4</td>\n      <td>Nice Taffy</td>\n      <td>I got a wild hair for taffy and ordered this f...</td>\n      <td>Title: Nice Taffy; Content: I got a wild hair ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>1340150400</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1SP2KVKFXXRU1</td>\n      <td>5</td>\n      <td>Great!  Just as good as the expensive brands!</td>\n      <td>This saltwater taffy had great flavors and was...</td>\n      <td>Title: Great!  Just as good as the expensive b...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>1336003200</td>\n      <td>B006K2ZZ7K</td>\n      <td>A3JRGQVEQN31IQ</td>\n      <td>5</td>\n      <td>Wonderful, tasty taffy</td>\n      <td>This taffy is so good.  It is very soft and ch...</td>\n      <td>Title: Wonderful, tasty taffy; Content: This t...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>1322006400</td>\n      <td>B000E7L2R4</td>\n      <td>A1MZYO9TZK0BBI</td>\n      <td>5</td>\n      <td>Yay Barley</td>\n      <td>Right now I'm mostly just sprouting this so my...</td>\n      <td>Title: Yay Barley; Content: Right now I'm most...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>1351209600</td>\n      <td>B00171APVA</td>\n      <td>A21BT40VZCCYT4</td>\n      <td>5</td>\n      <td>Healthy Dog Food</td>\n      <td>This is a very healthy dog food. Good for thei...</td>\n      <td>Title: Healthy Dog Food; Content: This is a ve...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 9
        },
        {
            "cell_type": "markdown",
            "source": [
                "Next we'll perform some light data cleaning by removing redundant whitespace and cleaning up the punctuation to prepare the data for tokenization. We will also remove comments that are too long for the token limit (8192 tokens)"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "027376ed-edc8-49ab-a361-a9aea8781b77"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\r\n",
                "import re\r\n",
                "import tiktoken\r\n",
                "import nltk\r\n",
                "from nltk.corpus import stopwords\r\n",
                "from nltk.tokenize import word_tokenize\r\n",
                "import string\r\n",
                "# Assuming you have already loaded your DataFrame 'df'\r\n",
                "\r\n",
                "# Remove null values\r\n",
                "df.dropna(subset=['combined'], inplace=True)\r\n",
                "\r\n",
                "# Convert to lowercase\r\n",
                "df['combined'] = df['combined'].str.lower()\r\n",
                "\r\n",
                "# Remove accented letters\r\n",
                "df['combined'] = df['combined'].apply(lambda x: re.sub(r'[^\\x00-\\x7F]+', '', x))\r\n",
                "\r\n",
                "# Remove punctuation marks\r\n",
                "translator = str.maketrans('', '', string.punctuation)\r\n",
                "df['combined'] = df['combined'].apply(lambda x: x.translate(translator))\r\n",
                "\r\n",
                "# Remove redundant white space\r\n",
                "df['combined'] = df['combined'].str.strip()\r\n",
                "\r\n",
                "# Remove stopwords using NLTK\r\n",
                "nltk.download('stopwords')\r\n",
                "stop_words = set(stopwords.words('english'))\r\n",
                "df['combined'] = df['combined'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\r\n",
                "\r\n",
                "# Remove Unicode characters (like emojis)\r\n",
                "df['combined'] = df['combined'].apply(lambda x: re.sub(r'[^\\x00-\\x7F]+', '', x))\r\n",
                "\r\n",
                "# Tokenize using tiktoken\r\n",
                "# Assuming you have already imported tiktoken and loaded the tokenizer\r\n",
                "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\r\n",
                "# Convert the list of tokens to a single integer (assuming each list contains token IDs)\r\n",
                "df['n_tokens'] = df['combined'].apply(lambda x: len(tokenizer.encode(x)))\r\n",
                "# Filter rows where 'n_tokens' is less than 8000\r\n",
                "df = df[df['n_tokens'] < 8000]\r\n",
                "\r\n",
                "\r\n",
                "# Print the modified DataFrame\r\n",
                "print(df.head(2))\r\n",
                ""
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "3146e381-1ff7-4932-a457-60564daf1b7f"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\pookam\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "   Id        Time   ProductId          UserId  Score                Summary  \\\n0   1  1303862400  B001E4KFG0  A3SGXH7AUHU8GW      5  Good Quality Dog Food   \n1   2  1346976000  B00813GRG4  A1D87F6ZCVE5NK      1      Not as Advertised   \n\n                                                Text  \\\n0  I have bought several of the Vitality canned d...   \n1  Product arrived labeled as Jumbo Salted Peanut...   \n\n                                            combined  n_tokens  \n0  title good quality dog food content bought sev...        32  \n1  title advertised content product arrived label...        27  \n"
                }
            ],
            "execution_count": 10
        },
        {
            "cell_type": "markdown",
            "source": [
                "The n\\_tokens column is simply a way of making sure none of the data we pass to the model for tokenization and embedding exceeds the input token limit of 8,192. When we pass the comment to the embeddings model, it will break the comment into tokens similar (though not necessarily identical) to the examples above and then convert the tokens to a series of floating point numbers that will be accessible via vector search. These embeddings can be stored locally or in an [Azure SQL Database to support Vector Search.](https:\\learn.microsoft.com\\en-us\\azure\\azure-sql\\database\\ai-artificial-intelligence-intelligent-applications?view=azuresql)  \n",
                "\n",
                "As a result, each **combined** (Product summary + Review) comment will have its own corresponding embedding vector in the new vector column on the right side of the DataFrame."
            ],
            "metadata": {
                "azdata_cell_guid": "780449e5-f623-4f73-a992-105bbffe00dc"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "sample_encode = tokenizer.encode(df.combined[5]) \r\n",
                "decode = tokenizer.decode_tokens_bytes(sample_encode)\r\n",
                "decode"
            ],
            "metadata": {
                "azdata_cell_guid": "7cbd3730-2106-4124-b9a4-117acd8a3a99",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 11,
                    "data": {
                        "text/plain": "[b'title',\n b' nice',\n b' t',\n b'aff',\n b'y',\n b' content',\n b' got',\n b' wild',\n b' hair',\n b' t',\n b'aff',\n b'y',\n b' ordered',\n b' five',\n b' pound',\n b' bag',\n b' t',\n b'aff',\n b'y',\n b' enjoyable',\n b' many',\n b' flavors',\n b' water',\n b'melon',\n b' root',\n b' beer',\n b' mel',\n b'on',\n b' pepp',\n b'ermint',\n b' grape',\n b' etc',\n b' complaint',\n b' bit',\n b' much',\n b' re',\n b'dbl',\n b'ack',\n b' lic',\n b'or',\n b'ice',\n b'fl',\n b'avored',\n b' pieces',\n b' particular',\n b' favorites',\n b' kids',\n b' husband',\n b' lasted',\n b' two',\n b' weeks',\n b' would',\n b' recommend',\n b' brand',\n b' t',\n b'aff',\n b'y',\n b' delightful',\n b' treat']"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 11
        },
        {
            "cell_type": "markdown",
            "source": [
                "We will now **generate the embeddings** for the 'combined' column using the **get\\_embeddings** function we had defined earlier.  \n",
                "We now have an additional column in the dataframe called vector which has the embeddings.\n",
                "\n",
                "This will take sometime depending on the Service Tier of Azure Open AI resource you have. For script with retry logic if you need to generate larger number of embeddings please refer to this example script"
            ],
            "metadata": {
                "azdata_cell_guid": "02dd23b3-a622-429d-b680-274efad2c3b4"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\r\n",
                "\r\n",
                "# Assuming you have a DataFrame 'df' with a 'combined' column\r\n",
                "# and you want to apply 'get_embeddings' to each batch of 100 rows\r\n",
                "\r\n",
                "batch_size = 100\r\n",
                "num_batches = len(df) // batch_size\r\n",
                "\r\n",
                "# Initialize an empty list to store the results\r\n",
                "all_embeddings = []\r\n",
                "\r\n",
                "for i in range(num_batches):\r\n",
                "    start_idx = i * batch_size\r\n",
                "    end_idx = (i + 1) * batch_size\r\n",
                "\r\n",
                "    # Get the current batch\r\n",
                "    current_batch = df.iloc[start_idx:end_idx]\r\n",
                "\r\n",
                "    # Apply your function to the 'combined' column\r\n",
                "    batch_embeddings = current_batch['combined'].apply(get_embedding)\r\n",
                "\r\n",
                "    # Append the batch results to the list\r\n",
                "    all_embeddings.extend(batch_embeddings)\r\n",
                "    print(f\"Batch {i+1} completed. Processed {end_idx} rows.\")\r\n",
                "\r\n",
                "# Create a new column 'vector' with the combined embeddings\r\n",
                "df['vector'] = all_embeddings\r\n",
                "\r\n",
                "# Print the updated DataFrame\r\n",
                "df.head(2)\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "a6e49745-42d0-4484-a90d-c1a9a88f9b3d",
                "language": "python",
                "tags": []
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Batch 1 completed. Processed 100 rows.\n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Batch 2 completed. Processed 200 rows.\n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Batch 3 completed. Processed 300 rows.\n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Batch 4 completed. Processed 400 rows.\n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Batch 5 completed. Processed 500 rows.\n"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 12,
                    "data": {
                        "text/plain": "   Id        Time   ProductId          UserId  Score                Summary  \\\n0   1  1303862400  B001E4KFG0  A3SGXH7AUHU8GW      5  Good Quality Dog Food   \n1   2  1346976000  B00813GRG4  A1D87F6ZCVE5NK      1      Not as Advertised   \n\n                                                Text  \\\n0  I have bought several of the Vitality canned d...   \n1  Product arrived labeled as Jumbo Salted Peanut...   \n\n                                            combined  n_tokens  \\\n0  title good quality dog food content bought sev...        32   \n1  title advertised content product arrived label...        27   \n\n                                              vector  \n0  [0.02559923, -0.018715078, -0.02559923, -0.028...  \n1  [0.0077655376, -0.01543994, -0.017482903, 0.01...  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Time</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>Score</th>\n      <th>Summary</th>\n      <th>Text</th>\n      <th>combined</th>\n      <th>n_tokens</th>\n      <th>vector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1303862400</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>5</td>\n      <td>Good Quality Dog Food</td>\n      <td>I have bought several of the Vitality canned d...</td>\n      <td>title good quality dog food content bought sev...</td>\n      <td>32</td>\n      <td>[0.02559923, -0.018715078, -0.02559923, -0.028...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1346976000</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>1</td>\n      <td>Not as Advertised</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n      <td>title advertised content product arrived label...</td>\n      <td>27</td>\n      <td>[0.0077655376, -0.01543994, -0.017482903, 0.01...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 12
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Part 2) Store & Query embeddings in Azure SQL DB."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "f9478fe8-be9f-4ecf-b197-2b6a0bf30ff0"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "You can import this [finefoodembeddings.csv](https:\\github.com\\Azure-Samples\\azure-sql-db-vector-search\\blob\\a181e15337402e568f4fc66fe5941e5973171972\\VectorSearch_Notebooks\\Datasets\\finefoodembeddings.csv) with precalculated embeddings directly to your SQL table if you have not performed the above steps."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "5b6fb279-bae3-479d-b235-c966587cb04f"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\r\n",
                "\r\n",
                "# load & inspect dataset\r\n",
                "df = pd.read_csv(r\"AzureSQLVectorSearch\\Dataset\\finefoodembeddings.csv\")\r\n",
                "df.head(2)"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "45013e22-b118-4da9-b27a-bfabcf1ee869"
            },
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 13,
                    "data": {
                        "text/plain": "   Unnamed: 0  Id        Time   ProductId          UserId  Score  \\\n0           0   1  1303862400  B001E4KFG0  A3SGXH7AUHU8GW      5   \n1           1   2  1346976000  B00813GRG4  A1D87F6ZCVE5NK      1   \n\n                 Summary                                               Text  \\\n0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n\n                                            combined  \\\n0  Title: Good Quality Dog Food; Content: I have ...   \n1  Title: Not as Advertised; Content: Product arr...   \n\n                                              vector  \n0  [0.02088439, -0.00022463033, -0.0019172364, -0...  \n1  [-0.0044591213, 0.00078397157, -0.022424141, 0...  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Id</th>\n      <th>Time</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>Score</th>\n      <th>Summary</th>\n      <th>Text</th>\n      <th>combined</th>\n      <th>vector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1303862400</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>5</td>\n      <td>Good Quality Dog Food</td>\n      <td>I have bought several of the Vitality canned d...</td>\n      <td>Title: Good Quality Dog Food; Content: I have ...</td>\n      <td>[0.02088439, -0.00022463033, -0.0019172364, -0...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>1346976000</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>1</td>\n      <td>Not as Advertised</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n      <td>Title: Not as Advertised; Content: Product arr...</td>\n      <td>[-0.0044591213, 0.00078397157, -0.022424141, 0...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 13
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Connect to Azure SQL Database and load the data from the dataframe into a SQL Table\n",
                "\n",
                "We will insert our vectors into the SQL Table now. The table embeddings has a column called vector which is varbinary(8000) type. <span style=\"color: var(--vscode-foreground);\">Ensure you have created the table and index using the script</span> [createtable.sql](.\\AzureSQLVectorSearch\\src\\createtable.sql)\n",
                "\n",
                "<span style=\"color: var(--vscode-foreground);\">We will pass the vectors to the new built in function&nbsp;<b>JSON_ARRAY_TO_VECTOR</b>&nbsp;that will converts a JSON array to a compact&nbsp;<b>binary&nbsp;</b>representation of a vector.&nbsp;</span>  Vectors are stored in an efficient binary format that also enables usage of dedicated CPU vector processing extensions like SIMD and AVX.           \n",
                "\n",
                "On that table we can create a **column store index t**o efficiently store and search for vectors. Then it is just a matter of calculating the distance between vectors to find the closest. Thanks to the internal optimization of the columnstore (that uses SIMD AVX-512 instructions to speed up vector operations) the distance calculation to find the exact nearest neighbour search is extremely fast."
            ],
            "metadata": {
                "azdata_cell_guid": "bd6cb5e4-8207-4003-bce4-a1d7daf28e5c"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import os\r\n",
                "from dotenv import load_dotenv\r\n",
                "import pyodbc\r\n",
                "import struct\r\n",
                "from azure.identity import DefaultAzureCredential\r\n",
                "\r\n",
                "# Load environment variables from .env file\r\n",
                "load_dotenv()\r\n",
                "\r\n",
                "# Retrieve the connection string from the environment variables\r\n",
                "entra_connection_string = os.getenv('ENTRA_CONNECTION_STRING')\r\n",
                "sql_connection_string = os.getenv('SQL_CONNECTION_STRING')\r\n",
                "\r\n",
                "# Determine the authentication method and connect to the database\r\n",
                "if entra_connection_string:\r\n",
                "    # Entra ID Service Principle Authentication\r\n",
                "    credential = DefaultAzureCredential()\r\n",
                "    token = credential.get_token('https://database.windows.net/.default')\r\n",
                "    token_bytes = token.token.encode('UTF-16LE')\r\n",
                "    token_struct = struct.pack(f'<I{len(token_bytes)}s', len(token_bytes), token_bytes)\r\n",
                "    SQL_COPT_SS_ACCESS_TOKEN = 1256  # This connection option is defined by Microsoft in msodbcsql.h\r\n",
                "    conn = pyodbc.connect(entra_connection_string, attrs_before={SQL_COPT_SS_ACCESS_TOKEN: token_struct})\r\n",
                "elif sql_connection_string:\r\n",
                "    # SQL Authentication\r\n",
                "    conn = pyodbc.connect(sql_connection_string)\r\n",
                "else:\r\n",
                "    raise ValueError(\"No valid connection string found in the environment variables.\")\r\n",
                "\r\n",
                "# Create a cursor object\r\n",
                "cursor = conn.cursor()\r\n",
                "\r\n",
                "# Enable fast_executemany\r\n",
                "cursor.fast_executemany = True\r\n",
                "\r\n",
                "# Assuming 'df' is your DataFrame and it's already defined\r\n",
                "# Prepare your data to be inserted as a list of tuples\r\n",
                "data_to_insert = [\r\n",
                "    (\r\n",
                "        row['Id'],\r\n",
                "        row['ProductId'],\r\n",
                "        row['UserId'],\r\n",
                "        row['Score'],\r\n",
                "        row['Summary'],\r\n",
                "        row['Text'],\r\n",
                "        row['combined'],\r\n",
                "        row['vector']\r\n",
                "    ) for index, row in df.iterrows()\r\n",
                "]\r\n",
                "\r\n",
                "# Define your SQL insert query. \r\n",
                "#We are using the JSON_ARRAY_TO_VECTOR function here which  converts the jsonarray to a compact binary representation of the vector\r\n",
                "insert_query = \"\"\"\r\n",
                "INSERT INTO embeddings (Id, ProductId, UserId, score, summary, text, combined, vector)\r\n",
                "VALUES (?, ?, ?, ?, ?, ?, ?, JSON_ARRAY_TO_VECTOR(CAST(? AS VARCHAR(MAX))))\r\n",
                "\"\"\"\r\n",
                "\r\n",
                "# Execute batch insert\r\n",
                "cursor.executemany(insert_query, data_to_insert)\r\n",
                "\r\n",
                "# Commit the transaction\r\n",
                "conn.commit()\r\n",
                "\r\n",
                "# Print a success message\r\n",
                "print(\"Data inserted successfully into the 'embeddings' table.\")\r\n",
                "\r\n",
                "# Close the cursor and connection\r\n",
                "cursor.close()\r\n",
                "conn.close()\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "b54b85a0-4966-43f5-b26c-984145cf9f32",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Data inserted successfully into the 'embeddings' table.\n"
                }
            ],
            "execution_count": 37
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Using the native vector functions in SQL DB\n",
                "\n",
                "Lets take a look at how the vector is stored in the SQL DB table & also  <span style=\"color: var(--vscode-foreground);\">&nbsp;make use of the newly introduced helper functions</span>\n",
                "\n",
                "**ISVECTOR** Checks if the provided object is a valid vector: Returns 1 if valid, otherwise returns 0. Returns NULL if the expression is NULL\n",
                "\n",
                "**VECTOR\\_DIMENSIONS** Takes a vector as an input and returns the number of dimensions as an output. In this case we see the number of dimensions of the vector are 1536 (as we are using Azure OpenAI text embeddings)\n",
                "\n",
                "**VECTOR\\_TO\\_JSON\\_ARRAY** Converts a vector in a compact binary format to a human-readable string format. The string format is the same as the one used by JSON to represent arrays"
            ],
            "metadata": {
                "azdata_cell_guid": "0f8850d8-8e41-4a43-a046-e796bcd11fdf"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "from prettytable import PrettyTable\r\n",
                "\r\n",
                "# Determine the authentication method and connect to the database\r\n",
                "if entra_connection_string:\r\n",
                "    # Entra ID Service Principle Authentication\r\n",
                "    credential = DefaultAzureCredential()\r\n",
                "    token = credential.get_token('https://database.windows.net/.default')\r\n",
                "    token_bytes = token.token.encode('UTF-16LE')\r\n",
                "    token_struct = struct.pack(f'<I{len(token_bytes)}s', len(token_bytes), token_bytes)\r\n",
                "    SQL_COPT_SS_ACCESS_TOKEN = 1256  # This connection option is defined by Microsoft in msodbcsql.h\r\n",
                "    conn = pyodbc.connect(entra_connection_string, attrs_before={SQL_COPT_SS_ACCESS_TOKEN: token_struct})\r\n",
                "elif sql_connection_string:\r\n",
                "    # SQL Authentication\r\n",
                "    conn = pyodbc.connect(sql_connection_string)\r\n",
                "else:\r\n",
                "    raise ValueError(\"No valid connection string found in the environment variables.\")\r\n",
                "\r\n",
                "# Create a cursor object\r\n",
                "cursor = conn.cursor()\r\n",
                "\r\n",
                "# Use placeholders for the parameters in the SQL query\r\n",
                "query = \"SELECT TOP(10) ISVECTOR(vector) as isvector, VECTOR_DIMENSIONS(vector) as dimensions , summary , vector , VECTOR_TO_JSON_ARRAY(vector) as jsonvector,  ProductId FROM dbo.embeddings\"\r\n",
                "\r\n",
                "# Execute the query with the parameters\r\n",
                "cursor.execute(query)\r\n",
                "queryresults = cursor.fetchall()\r\n",
                "\r\n",
                "# Get column names from cursor.description\r\n",
                "column_names = [column[0] for column in cursor.description]\r\n",
                "\r\n",
                "# Create a PrettyTable object\r\n",
                "table = PrettyTable()\r\n",
                "\r\n",
                "# Add column names to the table\r\n",
                "table.field_names = column_names\r\n",
                "\r\n",
                "# Set max width for each column to truncate data\r\n",
                "table.max_width = 20\r\n",
                "\r\n",
                "# Add rows to the table\r\n",
                "for row in queryresults:\r\n",
                "    # Truncate each value to 20 characters\r\n",
                "    truncated_row = [str(value)[:20] for value in row]\r\n",
                "    table.add_row(truncated_row)\r\n",
                "\r\n",
                "# Print the table\r\n",
                "print(table)\r\n",
                "\r\n",
                "# Commit the changes\r\n",
                "conn.commit()\r\n",
                "# Close the connection\r\n",
                "conn.close()\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "37251f52-1d9b-4ed7-8404-67eb9dd88d69",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "+----------+------------+----------------------+----------------------+----------------------+------------+\n| isvector | dimensions |       summary        |        vector        |      jsonvector      | ProductId  |\n+----------+------------+----------------------+----------------------+----------------------+------------+\n|    1     |    1536    | Good Quality Dog Foo | b'\\xa9\\x01\\x00\\x06\\x | [0.0208843909204006, | B001E4KFG0 |\n|    1     |    1536    |  Not as Advertised   | b'\\xa9\\x01\\x00\\x06\\x | [-0.0044591212645173 | B00813GRG4 |\n|    1     |    1536    | \"Delight\" says it al | b'\\xa9\\x01\\x00\\x06\\x | [0.0197708476334810, | B000LQOCH0 |\n|    1     |    1536    |    Cough Medicine    | b'\\xa9\\x01\\x00\\x06\\x | [-0.0131307244300842 | B000UA0QIQ |\n|    1     |    1536    |     Great taffy      | b'\\xa9\\x01\\x00\\x06\\x | [0.0057999598793685, | B006K2ZZ7K |\n|    1     |    1536    |      Nice Taffy      | b'\\xa9\\x01\\x00\\x06\\x | [0.0326173491775990, | B006K2ZZ7K |\n|    1     |    1536    | Great!  Just as good | b'\\xa9\\x01\\x00\\x06\\x | [0.0069001410156488, | B006K2ZZ7K |\n|    1     |    1536    | Wonderful, tasty taf | b'\\xa9\\x01\\x00\\x06\\x | [0.0117541579529643, | B006K2ZZ7K |\n|    1     |    1536    |      Yay Barley      | b'\\xa9\\x01\\x00\\x06\\x | [-0.0288896169513464 | B000E7L2R4 |\n|    1     |    1536    |   Healthy Dog Food   | b'\\xa9\\x01\\x00\\x06\\x | [0.0055382279679179, | B00171APVA |\n+----------+------------+----------------------+----------------------+----------------------+------------+\n"
                }
            ],
            "execution_count": 45
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Performing Vector Similarity Search in Azure SQL DB\n",
                "\n",
                "Lets now query our embedding table to get the top similar reviews given the _User search_ query.\n",
                "\n",
                "What we are doing: Given any user search query, we can get the vector representation of that text.   \n",
                "\n",
                "<span style=\"color: var(--vscode-foreground);\">Then we can use that vector to calculate the cosine distance against all the customer review comments stored in the database and take only the closest ones which will return the product most likely connect to the product we are interested in. The reviews with the highest similarity are considered the most relevant to the query, helping users discover products or experiences related to their search.</span>\n",
                "\n",
                "The most common distance is the cosine similarity, which can be calculated quite easily in SQL with the help of the new distance functions.\n",
                "\n",
                "**VECTOR\\_DISTANCE**( 'distance metric' , V1, V2)\n",
                "\n",
                "<span style=\"color: var(--vscode-foreground);\">We can use&nbsp;</span>  **cosine**  <span style=\"color: var(--vscode-foreground);\">&nbsp;,&nbsp;</span>  **euclidean**  <span style=\"color: var(--vscode-foreground);\">&nbsp;and&nbsp;</span>  **dot**  <span style=\"color: var(--vscode-foreground);\">&nbsp;as the distance metric today</span>\n",
                "\n",
                "We will define the function <span style=\"color: rgb(121, 94, 38); font-family: Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; white-space: pre;\">vector_search_sql</span>"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "356e7a68-c999-42de-9fe5-12f5f18d0f20"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import os\r\n",
                "import json\r\n",
                "from dotenv import load_dotenv\r\n",
                "import pyodbc\r\n",
                "import struct\r\n",
                "from azure.identity import DefaultAzureCredential\r\n",
                "\r\n",
                "def vector_search_sql(query, num_results=5):\r\n",
                "    # Load environment variables from .env file\r\n",
                "    load_dotenv()\r\n",
                "\r\n",
                "    # Retrieve the connection string from the environment variables\r\n",
                "    entra_connection_string = os.getenv('ENTRA_CONNECTION_STRING')\r\n",
                "    sql_connection_string = os.getenv('SQL_CONNECTION_STRING')\r\n",
                "\r\n",
                "    # Determine the authentication method and connect to the database\r\n",
                "    if entra_connection_string:\r\n",
                "        # Entra ID Service Principle Authentication\r\n",
                "        credential = DefaultAzureCredential()\r\n",
                "        token = credential.get_token('https://database.windows.net/.default')\r\n",
                "        token_bytes = token.token.encode('UTF-16LE')\r\n",
                "        token_struct = struct.pack(f'<I{len(token_bytes)}s', len(token_bytes), token_bytes)\r\n",
                "        SQL_COPT_SS_ACCESS_TOKEN = 1256  # This connection option is defined by Microsoft in msodbcsql.h\r\n",
                "        conn = pyodbc.connect(entra_connection_string, attrs_before={SQL_COPT_SS_ACCESS_TOKEN: token_struct})\r\n",
                "    elif sql_connection_string:\r\n",
                "        # SQL Authentication\r\n",
                "        conn = pyodbc.connect(sql_connection_string)\r\n",
                "    else:\r\n",
                "        raise ValueError(\"No valid connection string found in the environment variables.\")\r\n",
                "\r\n",
                "    # Create a cursor object\r\n",
                "    cursor = conn.cursor()\r\n",
                "\r\n",
                "    # Generate the query embedding for the user's search query\r\n",
                "    user_query_embedding = get_embedding(query)\r\n",
                "\r\n",
                "    # Convert user_query_embedding to a JSON string\r\n",
                "    user_query_embedding_json = json.dumps(user_query_embedding)\r\n",
                "\r\n",
                "    # SQL query for similarity search using the function vector_distance to calculate cosine similarity\r\n",
                "    sql_similarity_search = \"\"\"\r\n",
                "    SELECT TOP(?) ProductId, Summary, text,\r\n",
                "           1 - vector_distance('cosine', JSON_ARRAY_TO_VECTOR(cast(? as varchar(max))), [vector]) AS similarity_score\r\n",
                "    FROM dbo.embeddings\r\n",
                "    ORDER BY similarity_score desc\r\n",
                "    \"\"\"\r\n",
                "\r\n",
                "    cursor.execute(sql_similarity_search, (num_results, user_query_embedding_json))\r\n",
                "    results = cursor.fetchall()\r\n",
                "\r\n",
                "    # Close the database connection\r\n",
                "    conn.close()\r\n",
                "\r\n",
                "    return results\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "dc8b6a89-2894-4607-9549-a8502af81a2c",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 11
        },
        {
            "cell_type": "code",
            "source": [
                "# Assuming you have implemented the `vector_search_sql` function as shown earlier\r\n",
                "\r\n",
                "# Example usage\r\n",
                "query = \"oatmeal options for my toddler\"\r\n",
                "num_results = 4\r\n",
                "search_results = vector_search_sql(query, num_results)\r\n",
                "for result in search_results:\r\n",
                "    product_id = result[0]  # Assuming ProductId is the first column\r\n",
                "    summary = result [1]\r\n",
                "    text = result [2]\r\n",
                "    similarity_score = result[3]  # Assuming similarity_score is the third column\r\n",
                "    \r\n",
                "    print(f\"Product ID: {product_id}\")\r\n",
                "    print(f\"summary : {summary}\")\r\n",
                "    print (f\"Text : {text}\")\r\n",
                "    print(f\"Similarity Score: {similarity_score}\\n\")\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "5d77335d-3540-44bf-9e24-aa7037feddb0",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Product ID: B001DIM8K8\nsummary : Nothing like the crappy stuff I grew up on.\nText : My daughter and I eat low-carb. Which oatmeal is not really, by the way. But I was looking for something that we could eat in the morning that was not meat/dairy/egg, and was gluten-free, and filling, without being pure sugar like most breakfast foods and especially grains. I decided to try these long-cooking irish oats. We use 2 cups water and 1/2 cup dry oats, for 1/4cup dry each. It takes this stuff 30 minutes+ to cook so it is not fast food, for sure. But strangely enough, it's filling. Adding fats (couple tablespoons of cream) to the serving helps that of course. In any case, it is much tastier, and much more long-lasting for keeping us satisfied, than I expected, and surprisingly stable on blood sugar. Nor has it set off cravings like most grains, fruits, etc. do if we eat those; the sugars digest so slowly in this apparently. It is more solid and nutty than the flakey quick-oats I grew up with, which I now consider a gummy gluey sugarbomb insult to true oats. These are harder to find and cost more but they're worth it.\nSimilarity Score: 0.5673871961458196\n\nProduct ID: B001EO5QW8\nsummary : it's oatmeal\nText : What else do you need to know? Oatmeal, instant (make it with a half cup of low-fat milk and add raisins;nuke for 90 seconds). More expensive than Kroger store brand oatmeal and maybe a little tastier or better texture or something. It's still just oatmeal. Mmm, convenient!\nSimilarity Score: 0.5668513542501259\n\nProduct ID: B001DIM8K8\nsummary : Texture and the taste are totally different from the pressed oats!\nText : I have been having Quaker Oatmeal for yesrs until trying this today! The texture and the taste are completely different from the pressed oat. It worths cooking for half hour. My son love it at the first bite! My 8-month-old baby is also love it! I uaually cook the portion which will be enough for 2~3 days. Drop one spoon or two into the worm milk every morning to make my breakfast much more healthier! This one is so good that it will be hard for me to go back to pressed oatmeal.....\nSimilarity Score: 0.5633615577032233\n\nProduct ID: B001DIM8K8\nsummary : Slow cooking\nText : I'll be honest, if you want a quick breakfast don't purchase this oatmeal. But, if you have time to spare or don't mind waiting for some \"good eats\", this is the oatmeal for you.<br /><br />Step 1. pour some milk into a sauce pan; Step 2. add a dash of salt [or salt to taste]; Step 3. add oatmeal, making sure it stays covered by milk; Step 4. turn on stove to low heat [not too low but definitely not too high, as you don't want the milk to evaporate/dry out leaving you with tough oats in pan] and cover pan; Step 5. do some little cleaning to built up appetite making sure to ck on progress periodically; Step 6. add more milk if oats are still too tough and let it simmer for a little while longer; Step 7. get your ladle/just pour directing into a bowl add a few raisins/cranberries/your favorite dried fruit and ENJOY!\nSimilarity Score: 0.5528843265139003\n\n"
                }
            ],
            "execution_count": 12
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Part 3 - Use embeddings retrieved from a vector database to augment LLM generation\n",
                "\n",
                "Lets create a helper function to feed prompts into the [Completions model](https:\\learn.microsoft.com\\en-us\\azure\\ai-services\\openai\\concepts\\models#gpt-35-models) & create interactive loop where you can pose questions to the model and receive information grounded in your data.\n",
                "\n",
                "The function generate\\_completion is defined to help ground the GPT3.5 model with prompts and system instructions.   \n",
                "Note that we are passing the results of the vector\\_search\\_sql we defined earlier to the model and we define the system prompt .  \n",
                "We are using gpt-35-turbo-16k model here. \n",
                "\n",
                "You can get more information on using Azure Open AI GPT chat models [here](https:\\learn.microsoft.com\\en-us\\azure\\ai-services\\openai\\chatgpt-quickstart?tabs=command-line%2Cpython-new&pivots=programming-language-python)"
            ],
            "metadata": {
                "azdata_cell_guid": "a4919ceb-ae7c-415f-9872-4fc6b4e11c99"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import os\r\n",
                "from dotenv import load_dotenv\r\n",
                "from openai import AzureOpenAI\r\n",
                "\r\n",
                "# Load environment variables from .env file\r\n",
                "load_dotenv()\r\n",
                "\r\n",
                "# Retrieve the API key and endpoint from the environment variables\r\n",
                "api_key = os.getenv('AZURE_OPENAI_API_KEY')\r\n",
                "azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\r\n",
                "\r\n",
                "# Create a chat completion request\r\n",
                "client = AzureOpenAI(\r\n",
                "    api_key=api_key,\r\n",
                "    api_version=\"2023-05-15\",\r\n",
                "    azure_endpoint=azure_endpoint\r\n",
                ")\r\n",
                "\r\n",
                "\r\n",
                "def generate_completion(search_results, user_input):\r\n",
                "    system_prompt = '''\r\n",
                "You are an intelligent & funny assistant who will exclusively answer based on the data provided in the `search_results`:\r\n",
                "- Use the information from `search_results` to generate your responses. If the data is not a perfect match for the user's query, use your best judgment to provide helpful suggestions and include the following format:\r\n",
                "  Product ID: {product_id}\r\n",
                "  Summary: {summary}\r\n",
                "  Review: {text}\r\n",
                "  Similarity Score: {similarity_score}\r\n",
                "- Avoid any other external data sources.\r\n",
                "- Add a fun fact related to the overall product searched at the end of the recommendations.\r\n",
                "'''\r\n",
                "\r\n",
                "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\r\n",
                "    search_results = vector_search_sql(user_input, num_results)\r\n",
                "    \r\n",
                "    # Create an empty list to store the results\r\n",
                "    result_list = []\r\n",
                "\r\n",
                "    # Iterate through the search results and append relevant information to the list\r\n",
                "    for result in search_results:\r\n",
                "        product_id = result[0]  # Assuming ProductId is the first column\r\n",
                "        summary = result[1]\r\n",
                "        text = result[2]\r\n",
                "        similarity_score = result[3]  # Assuming similarity_score is the third column\r\n",
                "        \r\n",
                "        # Append the relevant information as a dictionary to the result_list\r\n",
                "        result_list.append({\r\n",
                "            \"product_id\": product_id,\r\n",
                "            \"summary\": summary,\r\n",
                "            \"text\": text,\r\n",
                "            \"similarity_score\": similarity_score\r\n",
                "        })\r\n",
                "\r\n",
                "    #print (result_list)\r\n",
                "    messages.append({\"role\": \"system\", \"content\": f\"{result_list}\"})\r\n",
                "    messages.append({\"role\": \"user\", \"content\": user_input})\r\n",
                "    response = client.chat.completions.create(model='chatcompletion', messages=messages, temperature=0) #replace with your model deployment name\r\n",
                "\r\n",
                "    return response.dict()"
            ],
            "metadata": {
                "azdata_cell_guid": "d2cf8d04-8323-4024-996c-f9e0acd1ef93",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 13
        },
        {
            "cell_type": "code",
            "source": [
                "# Create a loop of user input and model output to perform Q&A on the FineFoods Sample data\r\n",
                "\r\n",
                "print(\"*** What products are you looking for? Ask me & I can help you :) Type 'end' to end the session.\\n\")\r\n",
                "\r\n",
                "while True:\r\n",
                "    user_input = input(\"User prompt: \")\r\n",
                "    if user_input.lower() == \"end\":\r\n",
                "        break\r\n",
                "\r\n",
                "    # Print the user's question\r\n",
                "    print(f\"\\nUser asked: {user_input}\")\r\n",
                "\r\n",
                "    # Assuming vector_search_sql and generate_completion are defined functions that work correctly\r\n",
                "    search_results = vector_search_sql(user_input)\r\n",
                "    completions_results = generate_completion(search_results, user_input)\r\n",
                "\r\n",
                "    # Print the model's response\r\n",
                "    print(\"\\nAI's response:\")\r\n",
                "    print(completions_results['choices'][0]['message']['content'])\r\n",
                "\r\n",
                "# The loop will continue until the user types 'end'\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "57c6ba6b-8d63-4c21-a9d2-af7fec6d80f9",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "*** What products are you looking for? Ask me & I can help you :) Type 'end' to end the session.\n\n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "\nUser asked: can you suggest some canned food for my cat. Mind you he is very fussy!\n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "\nAI's response:\nI have found some canned cat food options that have received positive reviews from cat owners with picky eaters like yours. Here are a few recommendations:\n\nProduct ID: B002OHOC6A\nSummary: Cat food\nReview: My cat's favorite cat food! He is very picky and will not eat a lot of different cat foods, but he loves this one.\nSimilarity Score: 0.623\n\nProduct ID: B003SE19UK\nSummary: Palatable and healthy\nReview: Before I was educated about feline nutrition, I allowed my cats to become addicted to dry cat food. I always offered both canned and dry, but wish I would have fed them premium quality canned food and limited dry food. I have two 15-year-old cats and two 5-year-old cats. The only good quality dry foods they will eat are Wellness and Innova. Innova's manufacturer was recently purchased by Procter&Gamble. I began looking for a replacement. After once again offering several samples (from my local holistic pet store) Holistic Select was the only one (other than the usual Wellness and Innova) they would eat. For finicky cats, I recommend trying Holistic Select. It is a good quality food that is very palatable for finicky eaters.\nSimilarity Score: 0.616\n\nProduct ID: B002PNGY28\nSummary: Great soft little treats for your finicky feline\nReview: I have 2 cats. One will eat anything. The other one is soooo picky. She's had to have some of her teeth removed due to a mouth virus, so I needed to find some good soft treats. She likes these more than anything I've tried. They are really thin little tiny strips. I like Wellness, all-natural products. Both cats like their brand cat food as well.\nSimilarity Score: 0.615\n\nProduct ID: B000N5Z5RU\nSummary: My Picky Cat-Child Loves It\nReview: My youngest cat is very particular about what he eats. He absolutely will not eat if something doesn't meet his expectations. Between that and the recent pet food recalls, I've had a really hard time finding cat food that I can feed him. I'm happy to say that the Merrick Turducken clicks with him, plus it has no wheat gluten or other fillers. The texture of it is appealing, too... it's not just \"mush\" or Spam-looking like many foods. I'll continue to buy Turducken and plan to also try out some of the other Merrick flavors.\nSimilarity Score: 0.613\n\nFun Fact: Did you know that cats have taste buds that are more sensitive to bitterness than humans? This could be one reason why some cats are picky eaters!\n"
                }
            ],
            "execution_count": 14
        }
    ]
}