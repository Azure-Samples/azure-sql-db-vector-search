{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.8",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Create, store and query OpenAI embeddings in Azure SQL DB\n",
                "\n",
                "This notebook will teach you to:\n",
                "\n",
                "- How to create embeddings from content using the Azure OpenAI API\n",
                "- How to use Azure SQL DB as a vector database and store embeddings data in SQL & perform similarity search\n",
                "- How to use embeddings retrieved from a vector database to augment LLM generation.\n",
                "\n",
                "In this tutorial we will be using the [Fine Foods Review Dataset](https:\\www.kaggle.com\\datasets\\snap\\amazon-fine-food-reviews) available on Kaggle. This dataset consists of reviews of fine foods from amazon\n",
                "\n",
                "The CSV file is available here and we will be using a smaller sample for the tutorial.\n",
                "\n",
                "If you want to skip the steps of generating embeddings & directly load it in SQLDB to perform similarity search you can download the [finefoodembeddings.csv]() file that contains generated embeddings using text-embedding-small model from Azure OpenAI.\n",
                "\n",
                "This notebook contains some code snippets from the documentation [Explore Azure OpenAI Service embeddings Tutorial](https:\\learn.microsoft.com\\en-us\\azure\\ai-services\\openai\\tutorials\\embeddings?tabs=python-new%2Ccommand-line&pivots=programming-language-python)\n",
                "\n",
                "## Prerequisites:\n",
                "\n",
                "- An Azure subscription - [Create one for free](https:\\azure.microsoft.com\\free\\cognitive-services?azure-portal=true)\n",
                "    \n",
                "- Azure SQL Database - [Create one for free](https:\\learn.microsoft.com\\azure\\azure-sql\\database\\free-offer?view=azuresql)\n",
                "    \n",
                "- Access granted to Azure OpenAI in the desired Azure subscription. Currently, access to this service is granted only by application. You can apply for access to Azure OpenAI by completing the form at [https://aka.ms/oai/access](https:\\aka.ms\\oai\\access). Open an issue on this repo to contact us if you have an issue.\n",
                "    \n",
                "- An Azure OpenAI resource with the text-embedding-ada-002 (Version 2) model & gpt3.5 model deployed. This model is currently only available in [certain regions](https:\\learn.microsoft.com\\en-us\\azure\\ai-services\\openai\\concepts\\models#model-summary-table-and-region-availability). If you don't have a resource the process of creating one is documented in our [resource deployment guide](https:\\learn.microsoft.com\\en-us\\azure\\ai-services\\openai\\how-to\\create-resource).\n",
                "    \n",
                "- [Python 3.7.1 or later version](https:\\www.python.org\\)\n",
                "    \n",
                "- The following Python libraries: openai, num2words, matplotlib, plotly, scipy, scikit-learn, pandas, tiktoken.\n",
                "    \n",
                "- Jupyter Notebooks"
            ],
            "metadata": {
                "azdata_cell_guid": "a56b4788-b5d4-4314-82b6-9aa5c0bd4c81"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Create the table in the database\n",
                "\n",
                "SQL commands are in the [createtable.sql](AzureSQLVectorSearch\\src\\createtable.sql) script"
            ],
            "metadata": {
                "azdata_cell_guid": "eedcd374-2b80-4d09-b923-a64afb3df41a"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## .env file\n",
                "\n",
                "Fill out the .env file with your SQL server and Azure Open AI key and Endpoint values. \n",
                "\n",
                "For this notebook retrieve your key and endpoint as mentioned [here](https:\\learn.microsoft.com\\en-us\\azure\\ai-services\\openai\\tutorials\\embeddings?tabs=python-new%2Ccommand-line&pivots=programming-language-python#retrieve-key-and-endpoint)\n",
                "\n",
                "SQL Connection String details"
            ],
            "metadata": {
                "azdata_cell_guid": "418f24f1-1e37-4dc7-a7e2-d2008ea5851a"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Create embeddings from content using the Azure OpenAI API\n",
                "\n",
                "Note: If you want to skip the steps of generating embeddings & directly load it in SQLDB to perform similarity search you can directly skip to Part 2) Load and Store embeddings in Azure SQL DB"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "b0b8ed3a-2313-469c-a038-4ea72214bf97"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "#Setup the python libraries required for this notebook\r\n",
                "pip install -r requirements.txt"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "59dd0902-a737-4867-b4a3-11c5396a1fad"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "#Load the env details\r\n",
                "from dotenv import load_dotenv\r\n",
                "load_dotenv()\r\n",
                "\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "ab896eec-22dd-4a2d-ad5e-eab1d662fb52",
                "language": "python",
                "tags": []
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "True"
                    },
                    "metadata": {},
                    "execution_count": 18,
                    "output_type": "execute_result"
                }
            ],
            "execution_count": 18
        },
        {
            "cell_type": "markdown",
            "source": [
                "Lets define the function to generate embeddings from Azure Open AI text-embedding-small model.\n",
                "\n",
                "An embedding is a special format of data representation that can be easily utilized by machine learning models and algorithms. The embedding is an information dense representation of the semantic meaning of a piece of text.\n",
                "\n",
                "Each embedding is a vector of floating point numbers, such that the distance between two embeddings in the vector space is correlated with semantic similarity between two inputs in the original format. For example, if two texts are similar, then their vector representations should also be similar. Embeddings power vector similarity search in Azure SQL Database"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "ef9509c5-f27a-44ec-ade2-a2f8902e18c1"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import os\r\n",
                "import requests\r\n",
                "import sys\r\n",
                "from num2words import num2words\r\n",
                "import pandas as pd\r\n",
                "import numpy as np\r\n",
                "import tiktoken\r\n",
                "from openai import AzureOpenAI\r\n",
                "\r\n",
                "def get_embedding(text):\r\n",
                "    \"\"\"\r\n",
                "    Get sentence embedding using the Azure OpenAI text-embedding-small model.\r\n",
                "\r\n",
                "    Args:\r\n",
                "        text (str): Text to embed.\r\n",
                "\r\n",
                "    Returns:\r\n",
                "        dict: A dictionary containing the embedding.\r\n",
                "    \"\"\"\r\n",
                "    response = requests.post(openai_url,\r\n",
                "        headers={\"api-key\": openai_key, \"Content-Type\": \"application/json\"},\r\n",
                "        json={\"input\": [text]}  # Embed a single sentence\r\n",
                "    )\r\n",
                "    embedding = response.json()['data'][0]['embedding']\r\n",
                "    return embedding"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "5357f9e6-1a24-474a-b3fc-147441e9b6c8"
            },
            "outputs": [],
            "execution_count": 8
        },
        {
            "cell_type": "markdown",
            "source": [
                "Now we need to read our csv file and create a pandas DataFrame. After the initial DataFrame is created, we can view the contents of the table by running the below. For the purpose of the quick embedding generation tutorial we will only use nrows = 500.\n",
                "\n",
                "In this tutorial we will be using the [Fine Foods Review Dataset](https:\\www.kaggle.com\\datasets\\snap\\amazon-fine-food-reviews) available on Kaggle. This dataset consists of reviews of fine foods from Amazon."
            ],
            "metadata": {
                "azdata_cell_guid": "0343bba0-01ea-4537-a793-adaadb904781"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\r\n",
                "\r\n",
                "# load & inspect dataset\r\n",
                "df = pd.read_csv(r\"C:\\Users\\pookam\\Downloads\\Reviews.csv\\Reviews.csv\" , nrows =500)\r\n",
                "df = df[[\"Id\" , \"Time\", \"ProductId\", \"UserId\", \"Score\", \"Summary\", \"Text\"]]\r\n",
                "df = df.dropna()\r\n",
                "df[\"combined\"] = (\r\n",
                "    \"Title: \" + df.Summary.str.strip() + \"; Content: \" + df.Text.str.strip()\r\n",
                ")\r\n",
                "df.head(10)"
            ],
            "metadata": {
                "azdata_cell_guid": "f6815045-f75d-4bba-960f-f76818baa592",
                "language": "python"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "   Id        Time   ProductId          UserId  Score  \\\n0   1  1303862400  B001E4KFG0  A3SGXH7AUHU8GW      5   \n1   2  1346976000  B00813GRG4  A1D87F6ZCVE5NK      1   \n2   3  1219017600  B000LQOCH0   ABXLMWJIXXAIN      4   \n3   4  1307923200  B000UA0QIQ  A395BORC6FGVXV      2   \n4   5  1350777600  B006K2ZZ7K  A1UQRSCLF8GW1T      5   \n5   6  1342051200  B006K2ZZ7K   ADT0SRK1MGOEU      4   \n6   7  1340150400  B006K2ZZ7K  A1SP2KVKFXXRU1      5   \n7   8  1336003200  B006K2ZZ7K  A3JRGQVEQN31IQ      5   \n8   9  1322006400  B000E7L2R4  A1MZYO9TZK0BBI      5   \n9  10  1351209600  B00171APVA  A21BT40VZCCYT4      5   \n\n                                         Summary  \\\n0                          Good Quality Dog Food   \n1                              Not as Advertised   \n2                          \"Delight\" says it all   \n3                                 Cough Medicine   \n4                                    Great taffy   \n5                                     Nice Taffy   \n6  Great!  Just as good as the expensive brands!   \n7                         Wonderful, tasty taffy   \n8                                     Yay Barley   \n9                               Healthy Dog Food   \n\n                                                Text  \\\n0  I have bought several of the Vitality canned d...   \n1  Product arrived labeled as Jumbo Salted Peanut...   \n2  This is a confection that has been around a fe...   \n3  If you are looking for the secret ingredient i...   \n4  Great taffy at a great price.  There was a wid...   \n5  I got a wild hair for taffy and ordered this f...   \n6  This saltwater taffy had great flavors and was...   \n7  This taffy is so good.  It is very soft and ch...   \n8  Right now I'm mostly just sprouting this so my...   \n9  This is a very healthy dog food. Good for thei...   \n\n                                            combined  \n0  Title: Good Quality Dog Food; Content: I have ...  \n1  Title: Not as Advertised; Content: Product arr...  \n2  Title: \"Delight\" says it all; Content: This is...  \n3  Title: Cough Medicine; Content: If you are loo...  \n4  Title: Great taffy; Content: Great taffy at a ...  \n5  Title: Nice Taffy; Content: I got a wild hair ...  \n6  Title: Great!  Just as good as the expensive b...  \n7  Title: Wonderful, tasty taffy; Content: This t...  \n8  Title: Yay Barley; Content: Right now I'm most...  \n9  Title: Healthy Dog Food; Content: This is a ve...  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Time</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>Score</th>\n      <th>Summary</th>\n      <th>Text</th>\n      <th>combined</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1303862400</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>5</td>\n      <td>Good Quality Dog Food</td>\n      <td>I have bought several of the Vitality canned d...</td>\n      <td>Title: Good Quality Dog Food; Content: I have ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1346976000</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>1</td>\n      <td>Not as Advertised</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n      <td>Title: Not as Advertised; Content: Product arr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1219017600</td>\n      <td>B000LQOCH0</td>\n      <td>ABXLMWJIXXAIN</td>\n      <td>4</td>\n      <td>\"Delight\" says it all</td>\n      <td>This is a confection that has been around a fe...</td>\n      <td>Title: \"Delight\" says it all; Content: This is...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1307923200</td>\n      <td>B000UA0QIQ</td>\n      <td>A395BORC6FGVXV</td>\n      <td>2</td>\n      <td>Cough Medicine</td>\n      <td>If you are looking for the secret ingredient i...</td>\n      <td>Title: Cough Medicine; Content: If you are loo...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1350777600</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1UQRSCLF8GW1T</td>\n      <td>5</td>\n      <td>Great taffy</td>\n      <td>Great taffy at a great price.  There was a wid...</td>\n      <td>Title: Great taffy; Content: Great taffy at a ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>1342051200</td>\n      <td>B006K2ZZ7K</td>\n      <td>ADT0SRK1MGOEU</td>\n      <td>4</td>\n      <td>Nice Taffy</td>\n      <td>I got a wild hair for taffy and ordered this f...</td>\n      <td>Title: Nice Taffy; Content: I got a wild hair ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>1340150400</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1SP2KVKFXXRU1</td>\n      <td>5</td>\n      <td>Great!  Just as good as the expensive brands!</td>\n      <td>This saltwater taffy had great flavors and was...</td>\n      <td>Title: Great!  Just as good as the expensive b...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>1336003200</td>\n      <td>B006K2ZZ7K</td>\n      <td>A3JRGQVEQN31IQ</td>\n      <td>5</td>\n      <td>Wonderful, tasty taffy</td>\n      <td>This taffy is so good.  It is very soft and ch...</td>\n      <td>Title: Wonderful, tasty taffy; Content: This t...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>1322006400</td>\n      <td>B000E7L2R4</td>\n      <td>A1MZYO9TZK0BBI</td>\n      <td>5</td>\n      <td>Yay Barley</td>\n      <td>Right now I'm mostly just sprouting this so my...</td>\n      <td>Title: Yay Barley; Content: Right now I'm most...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>1351209600</td>\n      <td>B00171APVA</td>\n      <td>A21BT40VZCCYT4</td>\n      <td>5</td>\n      <td>Healthy Dog Food</td>\n      <td>This is a very healthy dog food. Good for thei...</td>\n      <td>Title: Healthy Dog Food; Content: This is a ve...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {},
                    "execution_count": 9,
                    "output_type": "execute_result"
                }
            ],
            "execution_count": 9
        },
        {
            "cell_type": "markdown",
            "source": [
                "Next we'll perform some light data cleaning by removing redundant whitespace and cleaning up the punctuation to prepare the data for tokenization. We will also remove comments that are too long for the token limit (8192 tokens)"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "027376ed-edc8-49ab-a361-a9aea8781b77"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\r\n",
                "import re\r\n",
                "import tiktoken\r\n",
                "import nltk\r\n",
                "from nltk.corpus import stopwords\r\n",
                "from nltk.tokenize import word_tokenize\r\n",
                "import string\r\n",
                "# Assuming you have already loaded your DataFrame 'df'\r\n",
                "\r\n",
                "# Remove null values\r\n",
                "df.dropna(subset=['combined'], inplace=True)\r\n",
                "\r\n",
                "# Convert to lowercase\r\n",
                "df['combined'] = df['combined'].str.lower()\r\n",
                "\r\n",
                "# Remove accented letters\r\n",
                "df['combined'] = df['combined'].apply(lambda x: re.sub(r'[^\\x00-\\x7F]+', '', x))\r\n",
                "\r\n",
                "# Remove punctuation marks\r\n",
                "translator = str.maketrans('', '', string.punctuation)\r\n",
                "df['combined'] = df['combined'].apply(lambda x: x.translate(translator))\r\n",
                "\r\n",
                "# Remove redundant white space\r\n",
                "df['combined'] = df['combined'].str.strip()\r\n",
                "\r\n",
                "# Remove stopwords using NLTK\r\n",
                "nltk.download('stopwords')\r\n",
                "stop_words = set(stopwords.words('english'))\r\n",
                "df['combined'] = df['combined'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\r\n",
                "\r\n",
                "# Remove Unicode characters (like emojis)\r\n",
                "df['combined'] = df['combined'].apply(lambda x: re.sub(r'[^\\x00-\\x7F]+', '', x))\r\n",
                "\r\n",
                "# Tokenize using tiktoken\r\n",
                "# Assuming you have already imported tiktoken and loaded the tokenizer\r\n",
                "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\r\n",
                "# Convert the list of tokens to a single integer (assuming each list contains token IDs)\r\n",
                "df['n_tokens'] = df['combined'].apply(lambda x: len(tokenizer.encode(x)))\r\n",
                "# Filter rows where 'n_tokens' is less than 8000\r\n",
                "df = df[df['n_tokens'] < 8000]\r\n",
                "\r\n",
                "\r\n",
                "# Print the modified DataFrame\r\n",
                "print(df.head(2))\r\n",
                ""
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "3146e381-1ff7-4932-a457-60564daf1b7f"
            },
            "outputs": [
                {
                    "name": "stderr",
                    "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\pookam\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n",
                    "output_type": "stream"
                },
                {
                    "name": "stdout",
                    "text": "   Id        Time   ProductId          UserId  Score                Summary  \\\n0   1  1303862400  B001E4KFG0  A3SGXH7AUHU8GW      5  Good Quality Dog Food   \n1   2  1346976000  B00813GRG4  A1D87F6ZCVE5NK      1      Not as Advertised   \n\n                                                Text  \\\n0  I have bought several of the Vitality canned d...   \n1  Product arrived labeled as Jumbo Salted Peanut...   \n\n                                            combined  n_tokens  \n0  title good quality dog food content bought sev...        32  \n1  title advertised content product arrived label...        27  \n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 10
        },
        {
            "cell_type": "markdown",
            "source": [
                "The n\\_tokens column is simply a way of making sure none of the data we pass to the model for tokenization and embedding exceeds the input token limit of 8,192. When we pass the comment to the embeddings model, it will break the comment into tokens similar (though not necessarily identical) to the examples above and then convert the tokens to a series of floating point numbers that will be accessible via vector search. These embeddings can be stored locally or in an Azure SQL Database to support Vector Search.  \n",
                "As a result, each combined comment will have its own corresponding embedding vector in the new vector column on the right side of the DataFrame."
            ],
            "metadata": {
                "azdata_cell_guid": "780449e5-f623-4f73-a992-105bbffe00dc"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "sample_encode = tokenizer.encode(df.combined[5]) \r\n",
                "decode = tokenizer.decode_tokens_bytes(sample_encode)\r\n",
                "decode"
            ],
            "metadata": {
                "azdata_cell_guid": "7cbd3730-2106-4124-b9a4-117acd8a3a99",
                "language": "python"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "[b'title',\n b' nice',\n b' t',\n b'aff',\n b'y',\n b' content',\n b' got',\n b' wild',\n b' hair',\n b' t',\n b'aff',\n b'y',\n b' ordered',\n b' five',\n b' pound',\n b' bag',\n b' t',\n b'aff',\n b'y',\n b' enjoyable',\n b' many',\n b' flavors',\n b' water',\n b'melon',\n b' root',\n b' beer',\n b' mel',\n b'on',\n b' pepp',\n b'ermint',\n b' grape',\n b' etc',\n b' complaint',\n b' bit',\n b' much',\n b' re',\n b'dbl',\n b'ack',\n b' lic',\n b'or',\n b'ice',\n b'fl',\n b'avored',\n b' pieces',\n b' particular',\n b' favorites',\n b' kids',\n b' husband',\n b' lasted',\n b' two',\n b' weeks',\n b' would',\n b' recommend',\n b' brand',\n b' t',\n b'aff',\n b'y',\n b' delightful',\n b' treat']"
                    },
                    "metadata": {},
                    "execution_count": 11,
                    "output_type": "execute_result"
                }
            ],
            "execution_count": 11
        },
        {
            "cell_type": "markdown",
            "source": [
                "We will now generate the embeddings for the 'combined' column using the get\\_embeddings function we had defined earlier"
            ],
            "metadata": {
                "azdata_cell_guid": "02dd23b3-a622-429d-b680-274efad2c3b4"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\r\n",
                "\r\n",
                "# Assuming you have a DataFrame 'df' with a 'combined' column\r\n",
                "# and you want to apply 'get_embeddings' to each batch of 100 rows\r\n",
                "\r\n",
                "batch_size = 100\r\n",
                "num_batches = len(df) // batch_size\r\n",
                "\r\n",
                "# Initialize an empty list to store the results\r\n",
                "all_embeddings = []\r\n",
                "\r\n",
                "for i in range(num_batches):\r\n",
                "    start_idx = i * batch_size\r\n",
                "    end_idx = (i + 1) * batch_size\r\n",
                "\r\n",
                "    # Get the current batch\r\n",
                "    current_batch = df.iloc[start_idx:end_idx]\r\n",
                "\r\n",
                "    # Apply your function to the 'combined' column\r\n",
                "    batch_embeddings = current_batch['combined'].apply(get_embedding)\r\n",
                "\r\n",
                "    # Append the batch results to the list\r\n",
                "    all_embeddings.extend(batch_embeddings)\r\n",
                "    print(f\"Batch {i+1} completed. Processed {end_idx} rows.\")\r\n",
                "\r\n",
                "# Create a new column 'vector' with the combined embeddings\r\n",
                "df['vector'] = all_embeddings\r\n",
                "\r\n",
                "# Print the updated DataFrame\r\n",
                "df.head(2)\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "a6e49745-42d0-4484-a90d-c1a9a88f9b3d",
                "language": "python",
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Batch 1 completed. Processed 100 rows.\n",
                    "output_type": "stream"
                },
                {
                    "name": "stdout",
                    "text": "Batch 2 completed. Processed 200 rows.\n",
                    "output_type": "stream"
                },
                {
                    "name": "stdout",
                    "text": "Batch 3 completed. Processed 300 rows.\n",
                    "output_type": "stream"
                },
                {
                    "name": "stdout",
                    "text": "Batch 4 completed. Processed 400 rows.\n",
                    "output_type": "stream"
                },
                {
                    "name": "stdout",
                    "text": "Batch 5 completed. Processed 500 rows.\n",
                    "output_type": "stream"
                },
                {
                    "data": {
                        "text/plain": "   Id        Time   ProductId          UserId  Score                Summary  \\\n0   1  1303862400  B001E4KFG0  A3SGXH7AUHU8GW      5  Good Quality Dog Food   \n1   2  1346976000  B00813GRG4  A1D87F6ZCVE5NK      1      Not as Advertised   \n\n                                                Text  \\\n0  I have bought several of the Vitality canned d...   \n1  Product arrived labeled as Jumbo Salted Peanut...   \n\n                                            combined  n_tokens  \\\n0  title good quality dog food content bought sev...        32   \n1  title advertised content product arrived label...        27   \n\n                                              vector  \n0  [0.02559923, -0.018715078, -0.02559923, -0.028...  \n1  [0.0077655376, -0.01543994, -0.017482903, 0.01...  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Time</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>Score</th>\n      <th>Summary</th>\n      <th>Text</th>\n      <th>combined</th>\n      <th>n_tokens</th>\n      <th>vector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1303862400</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>5</td>\n      <td>Good Quality Dog Food</td>\n      <td>I have bought several of the Vitality canned d...</td>\n      <td>title good quality dog food content bought sev...</td>\n      <td>32</td>\n      <td>[0.02559923, -0.018715078, -0.02559923, -0.028...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1346976000</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>1</td>\n      <td>Not as Advertised</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n      <td>title advertised content product arrived label...</td>\n      <td>27</td>\n      <td>[0.0077655376, -0.01543994, -0.017482903, 0.01...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {},
                    "execution_count": 12,
                    "output_type": "execute_result"
                }
            ],
            "execution_count": 12
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Store & Query embeddings in Azure SQL DB."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "f9478fe8-be9f-4ecf-b197-2b6a0bf30ff0"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "You can import the CSV with precalculated embeddings directly to your SQL table if you have not performed the above steps"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "5b6fb279-bae3-479d-b235-c966587cb04f"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\r\n",
                "\r\n",
                "# load & inspect dataset\r\n",
                "df = pd.read_csv(r\"C:\\vectortest\\SQL-AI-samples\\AzureSQLVectorSearch\\Dataset\\finefoodembeddingslarge.csv\")\r\n",
                "df.head(2)"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "45013e22-b118-4da9-b27a-bfabcf1ee869"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "   Unnamed: 0  Id        Time   ProductId          UserId  Score  \\\n0           0   1  1303862400  B001E4KFG0  A3SGXH7AUHU8GW      5   \n1           1   2  1346976000  B00813GRG4  A1D87F6ZCVE5NK      1   \n\n                 Summary                                               Text  \\\n0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n\n                                            combined  \\\n0  Title: Good Quality Dog Food; Content: I have ...   \n1  Title: Not as Advertised; Content: Product arr...   \n\n                                              vector  \n0  [0.02088439, -0.00022463033, -0.0019172364, -0...  \n1  [-0.0044591213, 0.00078397157, -0.022424141, 0...  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Id</th>\n      <th>Time</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>Score</th>\n      <th>Summary</th>\n      <th>Text</th>\n      <th>combined</th>\n      <th>vector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1303862400</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>5</td>\n      <td>Good Quality Dog Food</td>\n      <td>I have bought several of the Vitality canned d...</td>\n      <td>Title: Good Quality Dog Food; Content: I have ...</td>\n      <td>[0.02088439, -0.00022463033, -0.0019172364, -0...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>1346976000</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>1</td>\n      <td>Not as Advertised</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n      <td>Title: Not as Advertised; Content: Product arr...</td>\n      <td>[-0.0044591213, 0.00078397157, -0.022424141, 0...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {},
                    "execution_count": 13,
                    "output_type": "execute_result"
                }
            ],
            "execution_count": 13
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Connect to Azure SQL Database and load the data from the dataframe into a SQL Table.**\n",
                "\n",
                "We will insert our vectors into the SQL Table now. The table embeddings has a column called vector which is varbinary(8000) type.\n",
                "\n",
                "<span style=\"color: var(--vscode-foreground);\">You can create the table and index using the script</span> [createtable.sql]()<span style=\"color: var(--vscode-foreground);\"><br></span><span style=\"color: var(--vscode-foreground);\"><br>We will pass the vectors to the new built in function&nbsp;<b>JSON_ARRAY_TO_VECTOR</b>&nbsp;that will converts a JSON array to a compact&nbsp;<b>binary&nbsp;</b>representation of a vector.&nbsp;</span>  <span style=\"color: var(--vscode-foreground); font-family: Calibri, sans-serif;\">Vectors are stored in an</span>  <span style=\"color: var(--vscode-foreground);\">&nbsp;efficient binary format&nbsp;</span>  <span style=\"color: var(--vscode-foreground); font-family: Calibri, sans-serif;\">that also enables usage of dedicated CPU vector processing extensions like SIMD and AVX.&nbsp;</span>       \n",
                "\n",
                "On that table we can create a **column store index t**o efficiently store and search for vectors. Then it is just a matter of calculating the distance between vectors to find the closest. Thanks to the internal optimization of the columnstore (that uses SIMD AVX-512 instructions to speed up vector operations) the distance calculation to find the exact nearest neighbour search is extremely fast."
            ],
            "metadata": {
                "azdata_cell_guid": "bd6cb5e4-8207-4003-bce4-a1d7daf28e5c"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import os\r\n",
                "from dotenv import load_dotenv\r\n",
                "import pyodbc\r\n",
                "import struct\r\n",
                "from azure.identity import DefaultAzureCredential\r\n",
                "\r\n",
                "# Load environment variables from .env file\r\n",
                "load_dotenv()\r\n",
                "\r\n",
                "# Retrieve the connection string from the environment variables\r\n",
                "entra_connection_string = os.getenv('ENTRA_CONNECTION_STRING')\r\n",
                "sql_connection_string = os.getenv('SQL_CONNECTION_STRING')\r\n",
                "\r\n",
                "# Determine the authentication method and connect to the database\r\n",
                "if entra_connection_string:\r\n",
                "    # Entra ID Service Principle Authentication\r\n",
                "    credential = DefaultAzureCredential()\r\n",
                "    token = credential.get_token('https://database.windows.net/.default')\r\n",
                "    token_bytes = token.token.encode('UTF-16LE')\r\n",
                "    token_struct = struct.pack(f'<I{len(token_bytes)}s', len(token_bytes), token_bytes)\r\n",
                "    SQL_COPT_SS_ACCESS_TOKEN = 1256  # This connection option is defined by Microsoft in msodbcsql.h\r\n",
                "    conn = pyodbc.connect(entra_connection_string, attrs_before={SQL_COPT_SS_ACCESS_TOKEN: token_struct})\r\n",
                "elif sql_connection_string:\r\n",
                "    # SQL Authentication\r\n",
                "    conn = pyodbc.connect(sql_connection_string)\r\n",
                "else:\r\n",
                "    raise ValueError(\"No valid connection string found in the environment variables.\")\r\n",
                "\r\n",
                "# Create a cursor object\r\n",
                "cursor = conn.cursor()\r\n",
                "\r\n",
                "# Enable fast_executemany\r\n",
                "cursor.fast_executemany = True\r\n",
                "\r\n",
                "# Assuming 'df' is your DataFrame and it's already defined\r\n",
                "# Prepare your data to be inserted as a list of tuples\r\n",
                "data_to_insert = [\r\n",
                "    (\r\n",
                "        row['Id'],\r\n",
                "        row['ProductId'],\r\n",
                "        row['UserId'],\r\n",
                "        row['Score'],\r\n",
                "        row['Summary'],\r\n",
                "        row['Text'],\r\n",
                "        row['combined'],\r\n",
                "        row['vector']\r\n",
                "    ) for index, row in df.iterrows()\r\n",
                "]\r\n",
                "\r\n",
                "# Define your SQL insert query. \r\n",
                "#We are using the JSON_ARRAY_TO_VECTOR function here which  converts the jsonarray to a compact binary representation of the vector\r\n",
                "insert_query = \"\"\"\r\n",
                "INSERT INTO embeddings (Id, ProductId, UserId, score, summary, text, combined, vector)\r\n",
                "VALUES (?, ?, ?, ?, ?, ?, ?, JSON_ARRAY_TO_VECTOR(CAST(? AS VARCHAR(MAX))))\r\n",
                "\"\"\"\r\n",
                "\r\n",
                "# Execute batch insert\r\n",
                "cursor.executemany(insert_query, data_to_insert)\r\n",
                "\r\n",
                "# Commit the transaction\r\n",
                "conn.commit()\r\n",
                "\r\n",
                "# Print a success message\r\n",
                "print(\"Data inserted successfully into the 'embeddings' table.\")\r\n",
                "\r\n",
                "# Close the cursor and connection\r\n",
                "cursor.close()\r\n",
                "conn.close()\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "b54b85a0-4966-43f5-b26c-984145cf9f32",
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Data inserted successfully into the 'embeddings' table.\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 37
        },
        {
            "cell_type": "markdown",
            "source": [
                "Lets take a look at how the vector is stored in the SQL DB table.\n",
                "\n",
                "We will also make use of the newly introduced helper functions\n",
                "\n",
                "**ISVECTOR** Checks if the provided object is a valid vector: Returns 1 if valid, otherwise returns 0. Returns NULL if the expression is NULL\n",
                "\n",
                "**VECTOR\\_DIMENSIONS** Takes a vector as an input and returns the number of dimensions as an output. In this case we see the number of dimensions of the vector are 1536 (as we are using Azure OpenAI text embeddings)\n",
                "\n",
                "**VECTOR\\_TO\\_JSON\\_ARRAY** Converts a vector in a compact binary format to a human-readable string format. The string format is the same as the one used by JSON to represent arrays"
            ],
            "metadata": {
                "azdata_cell_guid": "0f8850d8-8e41-4a43-a046-e796bcd11fdf"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "from prettytable import PrettyTable\r\n",
                "\r\n",
                "# Determine the authentication method and connect to the database\r\n",
                "if entra_connection_string:\r\n",
                "    # Entra ID Service Principle Authentication\r\n",
                "    credential = DefaultAzureCredential()\r\n",
                "    token = credential.get_token('https://database.windows.net/.default')\r\n",
                "    token_bytes = token.token.encode('UTF-16LE')\r\n",
                "    token_struct = struct.pack(f'<I{len(token_bytes)}s', len(token_bytes), token_bytes)\r\n",
                "    SQL_COPT_SS_ACCESS_TOKEN = 1256  # This connection option is defined by Microsoft in msodbcsql.h\r\n",
                "    conn = pyodbc.connect(entra_connection_string, attrs_before={SQL_COPT_SS_ACCESS_TOKEN: token_struct})\r\n",
                "elif sql_connection_string:\r\n",
                "    # SQL Authentication\r\n",
                "    conn = pyodbc.connect(sql_connection_string)\r\n",
                "else:\r\n",
                "    raise ValueError(\"No valid connection string found in the environment variables.\")\r\n",
                "\r\n",
                "# Create a cursor object\r\n",
                "cursor = conn.cursor()\r\n",
                "\r\n",
                "# Use placeholders for the parameters in the SQL query\r\n",
                "query = \"SELECT TOP(10) ISVECTOR(vector) as isvector, VECTOR_DIMENSIONS(vector) as dimensions , summary , vector , VECTOR_TO_JSON_ARRAY(vector) as jsonvector,  ProductId FROM dbo.embeddings\"\r\n",
                "\r\n",
                "# Execute the query with the parameters\r\n",
                "cursor.execute(query)\r\n",
                "queryresults = cursor.fetchall()\r\n",
                "\r\n",
                "# Get column names from cursor.description\r\n",
                "column_names = [column[0] for column in cursor.description]\r\n",
                "\r\n",
                "# Create a PrettyTable object\r\n",
                "table = PrettyTable()\r\n",
                "\r\n",
                "# Add column names to the table\r\n",
                "table.field_names = column_names\r\n",
                "\r\n",
                "# Set max width for each column to truncate data\r\n",
                "table.max_width = 20\r\n",
                "\r\n",
                "# Add rows to the table\r\n",
                "for row in queryresults:\r\n",
                "    # Truncate each value to 20 characters\r\n",
                "    truncated_row = [str(value)[:20] for value in row]\r\n",
                "    table.add_row(truncated_row)\r\n",
                "\r\n",
                "# Print the table\r\n",
                "print(table)\r\n",
                "\r\n",
                "# Commit the changes\r\n",
                "conn.commit()\r\n",
                "# Close the connection\r\n",
                "conn.close()\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "37251f52-1d9b-4ed7-8404-67eb9dd88d69",
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "+----------+------------+----------------------+----------------------+----------------------+------------+\n| isvector | dimensions |       summary        |        vector        |      jsonvector      | ProductId  |\n+----------+------------+----------------------+----------------------+----------------------+------------+\n|    1     |    1536    | Good Quality Dog Foo | b'\\xa9\\x01\\x00\\x06\\x | [0.0208843909204006, | B001E4KFG0 |\n|    1     |    1536    |  Not as Advertised   | b'\\xa9\\x01\\x00\\x06\\x | [-0.0044591212645173 | B00813GRG4 |\n|    1     |    1536    | \"Delight\" says it al | b'\\xa9\\x01\\x00\\x06\\x | [0.0197708476334810, | B000LQOCH0 |\n|    1     |    1536    |    Cough Medicine    | b'\\xa9\\x01\\x00\\x06\\x | [-0.0131307244300842 | B000UA0QIQ |\n|    1     |    1536    |     Great taffy      | b'\\xa9\\x01\\x00\\x06\\x | [0.0057999598793685, | B006K2ZZ7K |\n|    1     |    1536    |      Nice Taffy      | b'\\xa9\\x01\\x00\\x06\\x | [0.0326173491775990, | B006K2ZZ7K |\n|    1     |    1536    | Great!  Just as good | b'\\xa9\\x01\\x00\\x06\\x | [0.0069001410156488, | B006K2ZZ7K |\n|    1     |    1536    | Wonderful, tasty taf | b'\\xa9\\x01\\x00\\x06\\x | [0.0117541579529643, | B006K2ZZ7K |\n|    1     |    1536    |      Yay Barley      | b'\\xa9\\x01\\x00\\x06\\x | [-0.0288896169513464 | B000E7L2R4 |\n|    1     |    1536    |   Healthy Dog Food   | b'\\xa9\\x01\\x00\\x06\\x | [0.0055382279679179, | B00171APVA |\n+----------+------------+----------------------+----------------------+----------------------+------------+\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 45
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Query our embedding table to get the top similar reviews given the User search query.**\n",
                "\n",
                "What we are doing: Given any user search query, we can get the vector representation of that text.   <span style=\"color: var(--vscode-foreground);\">&nbsp;Then we can use that vector to calculate the cosine distance against all the customer review comments stored in the database and take only the closest ones which will return the product most likely connect to the product we are interested in. The reviews with the highest similarity are considered the most relevant to the query, helping users discover products or experiences related to their search.</span>\n",
                "\n",
                "The most common distance is the cosine similarity, which can be calculated quite easily in SQL with the help of the new distance functions.\n",
                "\n",
                "**VECTOR\\_DISTANCE**( 'distance metric' , V1, V2)\n",
                "\n",
                "We can use **cosine** , **euclidean** and **dot** as the distance metric today"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "356e7a68-c999-42de-9fe5-12f5f18d0f20"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import os\r\n",
                "import json\r\n",
                "from dotenv import load_dotenv\r\n",
                "import pyodbc\r\n",
                "import struct\r\n",
                "from azure.identity import DefaultAzureCredential\r\n",
                "\r\n",
                "def vector_search_sql(query, num_results=5):\r\n",
                "    # Load environment variables from .env file\r\n",
                "    load_dotenv()\r\n",
                "\r\n",
                "    # Retrieve the connection string from the environment variables\r\n",
                "    entra_connection_string = os.getenv('ENTRA_CONNECTION_STRING')\r\n",
                "    sql_connection_string = os.getenv('SQL_CONNECTION_STRING')\r\n",
                "\r\n",
                "    # Determine the authentication method and connect to the database\r\n",
                "    if entra_connection_string:\r\n",
                "        # Entra ID Service Principle Authentication\r\n",
                "        credential = DefaultAzureCredential()\r\n",
                "        token = credential.get_token('https://database.windows.net/.default')\r\n",
                "        token_bytes = token.token.encode('UTF-16LE')\r\n",
                "        token_struct = struct.pack(f'<I{len(token_bytes)}s', len(token_bytes), token_bytes)\r\n",
                "        SQL_COPT_SS_ACCESS_TOKEN = 1256  # This connection option is defined by Microsoft in msodbcsql.h\r\n",
                "        conn = pyodbc.connect(entra_connection_string, attrs_before={SQL_COPT_SS_ACCESS_TOKEN: token_struct})\r\n",
                "    elif sql_connection_string:\r\n",
                "        # SQL Authentication\r\n",
                "        conn = pyodbc.connect(sql_connection_string)\r\n",
                "    else:\r\n",
                "        raise ValueError(\"No valid connection string found in the environment variables.\")\r\n",
                "\r\n",
                "    # Create a cursor object\r\n",
                "    cursor = conn.cursor()\r\n",
                "\r\n",
                "    # Generate the query embedding for the user's search query\r\n",
                "    user_query_embedding = get_embedding(query)\r\n",
                "\r\n",
                "    # Convert user_query_embedding to a JSON string\r\n",
                "    user_query_embedding_json = json.dumps(user_query_embedding)\r\n",
                "\r\n",
                "    # SQL query for similarity search using the function vector_distance to calculate cosine similarity\r\n",
                "    sql_similarity_search = \"\"\"\r\n",
                "    SELECT TOP(?) ProductId, Summary, text,\r\n",
                "           1 - vector_distance('cosine', JSON_ARRAY_TO_VECTOR(cast(? as varchar(max))), [vector]) AS similarity_score\r\n",
                "    FROM dbo.embeddings\r\n",
                "    ORDER BY similarity_score desc\r\n",
                "    \"\"\"\r\n",
                "\r\n",
                "    cursor.execute(sql_similarity_search, (num_results, user_query_embedding_json))\r\n",
                "    results = cursor.fetchall()\r\n",
                "\r\n",
                "    # Close the database connection\r\n",
                "    conn.close()\r\n",
                "\r\n",
                "    return results\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "dc8b6a89-2894-4607-9549-a8502af81a2c",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 46
        },
        {
            "cell_type": "code",
            "source": [
                "# Assuming you have implemented the `vector_search_sql` function as shown earlier\r\n",
                "\r\n",
                "# Example usage\r\n",
                "query = \"oatmeal options for my toddler\"\r\n",
                "num_results = 4\r\n",
                "search_results = vector_search_sql(query, num_results)\r\n",
                "for result in search_results:\r\n",
                "    product_id = result[0]  # Assuming ProductId is the first column\r\n",
                "    summary = result [1]\r\n",
                "    text = result [2]\r\n",
                "    similarity_score = result[3]  # Assuming similarity_score is the third column\r\n",
                "    \r\n",
                "    print(f\"Product ID: {product_id}\")\r\n",
                "    print(f\"summary : {summary}\")\r\n",
                "    print (f\"Text : {text}\")\r\n",
                "    print(f\"Similarity Score: {similarity_score}\\n\")\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "5d77335d-3540-44bf-9e24-aa7037feddb0",
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Product ID: B001DIM8K8\nsummary : Nothing like the crappy stuff I grew up on.\nText : My daughter and I eat low-carb. Which oatmeal is not really, by the way. But I was looking for something that we could eat in the morning that was not meat/dairy/egg, and was gluten-free, and filling, without being pure sugar like most breakfast foods and especially grains. I decided to try these long-cooking irish oats. We use 2 cups water and 1/2 cup dry oats, for 1/4cup dry each. It takes this stuff 30 minutes+ to cook so it is not fast food, for sure. But strangely enough, it's filling. Adding fats (couple tablespoons of cream) to the serving helps that of course. In any case, it is much tastier, and much more long-lasting for keeping us satisfied, than I expected, and surprisingly stable on blood sugar. Nor has it set off cravings like most grains, fruits, etc. do if we eat those; the sugars digest so slowly in this apparently. It is more solid and nutty than the flakey quick-oats I grew up with, which I now consider a gummy gluey sugarbomb insult to true oats. These are harder to find and cost more but they're worth it.\nSimilarity Score: 0.5673871961458196\n\nProduct ID: B001EO5QW8\nsummary : it's oatmeal\nText : What else do you need to know? Oatmeal, instant (make it with a half cup of low-fat milk and add raisins;nuke for 90 seconds). More expensive than Kroger store brand oatmeal and maybe a little tastier or better texture or something. It's still just oatmeal. Mmm, convenient!\nSimilarity Score: 0.5668513542501259\n\nProduct ID: B001DIM8K8\nsummary : Texture and the taste are totally different from the pressed oats!\nText : I have been having Quaker Oatmeal for yesrs until trying this today! The texture and the taste are completely different from the pressed oat. It worths cooking for half hour. My son love it at the first bite! My 8-month-old baby is also love it! I uaually cook the portion which will be enough for 2~3 days. Drop one spoon or two into the worm milk every morning to make my breakfast much more healthier! This one is so good that it will be hard for me to go back to pressed oatmeal.....\nSimilarity Score: 0.5633615577032233\n\nProduct ID: B001DIM8K8\nsummary : Slow cooking\nText : I'll be honest, if you want a quick breakfast don't purchase this oatmeal. But, if you have time to spare or don't mind waiting for some \"good eats\", this is the oatmeal for you.<br /><br />Step 1. pour some milk into a sauce pan; Step 2. add a dash of salt [or salt to taste]; Step 3. add oatmeal, making sure it stays covered by milk; Step 4. turn on stove to low heat [not too low but definitely not too high, as you don't want the milk to evaporate/dry out leaving you with tough oats in pan] and cover pan; Step 5. do some little cleaning to built up appetite making sure to ck on progress periodically; Step 6. add more milk if oats are still too tough and let it simmer for a little while longer; Step 7. get your ladle/just pour directing into a bowl add a few raisins/cranberries/your favorite dried fruit and ENJOY!\nSimilarity Score: 0.5528843265139003\n\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 47
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Use embeddings retrieved from a vector database to augment LLM generation\n",
                "\n",
                "Lets create a helper function to feed prompts into the Completions model & create interactive loop where you can pose questions to the model and receive information grounded in your data.\n",
                "\n",
                "The function generate\\_completion is defined to help ground the GPT3.5 model with prompts and system instructions.   \n",
                "Note that we are passing the results of the vector\\_search\\_sql we defined earlier to the model and we define the system prompt .  \n",
                "We are using gpt-35-turbo-16k model here. \n",
                "\n",
                "You can get more information on using Azure Open AI GPT chat models [here](https:\\learn.microsoft.com\\en-us\\azure\\ai-services\\openai\\chatgpt-quickstart?tabs=command-line%2Cpython-new&pivots=programming-language-python)"
            ],
            "metadata": {
                "azdata_cell_guid": "a4919ceb-ae7c-415f-9872-4fc6b4e11c99"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import os\r\n",
                "from dotenv import load_dotenv\r\n",
                "from openai import AzureOpenAI\r\n",
                "\r\n",
                "# Load environment variables from .env file\r\n",
                "load_dotenv()\r\n",
                "\r\n",
                "# Retrieve the API key and endpoint from the environment variables\r\n",
                "api_key = os.getenv('AZURE_OPENAI_API_KEY')\r\n",
                "azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\r\n",
                "\r\n",
                "# Create a chat completion request\r\n",
                "client = AzureOpenAI(\r\n",
                "    api_key=api_key,\r\n",
                "    api_version=\"2023-05-15\",\r\n",
                "    azure_endpoint=azure_endpoint\r\n",
                ")\r\n",
                "\r\n",
                "\r\n",
                "def generate_completion(search_results, user_input):\r\n",
                "    system_prompt = '''\r\n",
                "You are an intelligent & funny assistant who will exclusively answer based on the data provided in the `search_results`:\r\n",
                "- Use the information from `search_results` to generate your responses. If the data is not a perfect match for the user's query, use your best judgment to provide helpful suggestions and include the following format:\r\n",
                "  Product ID: {product_id}\r\n",
                "  Summary: {summary}\r\n",
                "  Review: {text}\r\n",
                "  Similarity Score: {similarity_score}\r\n",
                "- Avoid any other external data sources.\r\n",
                "- Add a fun fact related to the overall product searched at the end of the recommendations.\r\n",
                "'''\r\n",
                "\r\n",
                "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\r\n",
                "    search_results = vector_search_sql(user_input, num_results)\r\n",
                "    \r\n",
                "    # Create an empty list to store the results\r\n",
                "    result_list = []\r\n",
                "\r\n",
                "    # Iterate through the search results and append relevant information to the list\r\n",
                "    for result in search_results:\r\n",
                "        product_id = result[0]  # Assuming ProductId is the first column\r\n",
                "        summary = result[1]\r\n",
                "        text = result[2]\r\n",
                "        similarity_score = result[3]  # Assuming similarity_score is the third column\r\n",
                "        \r\n",
                "        # Append the relevant information as a dictionary to the result_list\r\n",
                "        result_list.append({\r\n",
                "            \"product_id\": product_id,\r\n",
                "            \"summary\": summary,\r\n",
                "            \"text\": text,\r\n",
                "            \"similarity_score\": similarity_score\r\n",
                "        })\r\n",
                "\r\n",
                "    #print (result_list)\r\n",
                "    messages.append({\"role\": \"system\", \"content\": f\"{result_list}\"})\r\n",
                "    messages.append({\"role\": \"user\", \"content\": user_input})\r\n",
                "    response = client.chat.completions.create(model='chatcompletion', messages=messages, temperature=0) #replace with your model deployment name\r\n",
                "\r\n",
                "    return response.dict()"
            ],
            "metadata": {
                "azdata_cell_guid": "d2cf8d04-8323-4024-996c-f9e0acd1ef93",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 58
        },
        {
            "cell_type": "code",
            "source": [
                "# Create a loop of user input and model output to perform Q&A on the FineFoods Sample data\r\n",
                "\r\n",
                "print(\"*** What products are you looking for? Ask me & I can help you :) Type 'end' to end the session.\\n\")\r\n",
                "\r\n",
                "while True:\r\n",
                "    user_input = input(\"User prompt: \")\r\n",
                "    if user_input.lower() == \"end\":\r\n",
                "        break\r\n",
                "\r\n",
                "    # Print the user's question\r\n",
                "    print(f\"\\nUser asked: {user_input}\")\r\n",
                "\r\n",
                "    # Assuming vector_search_sql and generate_completion are defined functions that work correctly\r\n",
                "    search_results = vector_search_sql(user_input)\r\n",
                "    completions_results = generate_completion(search_results, user_input)\r\n",
                "\r\n",
                "    # Print the model's response\r\n",
                "    print(\"\\nAI's response:\")\r\n",
                "    print(completions_results['choices'][0]['message']['content'])\r\n",
                "\r\n",
                "# The loop will continue until the user types 'end'\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "57c6ba6b-8d63-4c21-a9d2-af7fec6d80f9",
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "*** What products are you looking for? Ask me & I can help you :) Type 'end' to end the session.\n\n",
                    "output_type": "stream"
                },
                {
                    "name": "stdout",
                    "text": "\nUser asked: What is the best frozen pizza you can recommend?\n",
                    "output_type": "stream"
                },
                {
                    "name": "stdout",
                    "text": "\nAI's response:\nBased on the search results, here are some recommendations for the best frozen pizza:\n\nProduct ID: B002R6X1K6\nSummary: The best pizza I have ever had!\nReview: I was so excited to get my whole wheat pizza dough. After ordering it, I got it two days later! The directions are easy to follow and the taste of the crust is phenomenal. The toppings I added to my pizza were shrimp, chicken, cherry tomatoes, Mexican cheese blend, and turkey Canadian bacon. The pizza turned out great! Only 8 Weight Watcher's Point Plus value per slice. This is a better alternative to other leading pizzas.\nSimilarity Score: 0.5200278573716447\n\nProduct ID: B0064R7FLA\nSummary: Antimo Capputo\nReview: This is the best flour for homemade pizza. It has the best tasting crust I have found. It works best in a super hot oven if you don't have a pizza oven.\nSimilarity Score: 0.4999896619370624\n\nProduct ID: B004391DK0\nSummary: Best Pizza since I have been gluten-free\nReview: I absolutely LOVE this product - being able to have pancakes was my original goal - however - I made the pizza with it & was absolutely thrilled about the pizza. These are small boxes (makes two pizzas per box), but I would highly recommend - I am reordering a pack of three now!\nSimilarity Score: 0.4904666435841486\n\nProduct ID: B004ASGJ5S\nSummary: As good as homemade\nReview: Don't be put off by the cartoon label: this is SERIOUS, EXCELLENT pizza sauce, the best I've ever tasted out of a can. My family has been eating it for years. Basically, there's no need for us to make homemade sauce anymore. But don't just believe me -- google \"Don Pepino pizza sauce\" and read other people's rave reviews. We can't find it in our local grocery stores, so we usually buy a case or two at a time. The pop-top cans are also a perfect size for a large pie or two. The company's other tomato products, sold under the name \"Sclafani\", are also highly recommended.\nSimilarity Score: 0.47008647309634743\n\nFun Fact: Did you know that the largest pizza ever made was 13,580.28 square feet? It was made in Rome, Italy in 2012. That's a lot of pizza!\n",
                    "output_type": "stream"
                },
                {
                    "name": "stdout",
                    "text": "\nUser asked: thanks thats sorted! Now show me options for canned food for my pet cat . It better be good because he is super fussy\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": null
        }
    ]
}